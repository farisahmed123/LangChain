{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87c17dc",
   "metadata": {},
   "source": [
    "# Middleware in LangChain \n",
    "mechanism that allows you to intercept, modify, or extend the behavior of chains and tools as they process inputs and outputs. It acts as a layer between the user and the core logic, enabling tasks like logging, validation, or custom processing without changing the main workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f56b5",
   "metadata": {},
   "source": [
    "## Example\n",
    "Suppose you want to check if a userâ€™s input contains any banned words before processing it in LangChain. You can use middleware to scan the input for banned words. If any are found, the middleware can block the request or return a warning, otherwise it lets the input continue to the main logic. This helps keep your application safe and clean without changing the core processing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca36eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000023178DCAFD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023178DCB9D0>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model('groq:qwen/qwen3-32b')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ccb18",
   "metadata": {},
   "source": [
    "### Summarization MiddleWare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e70d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model='groq:qwen/qwen3-32b',\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model='groq:qwen/qwen3-32b',\n",
    "            trigger = (\"messages\",10),\n",
    "            keep = (\"messages\",4)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8debef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run with thread ID\n",
    "config={\"configurable\":{\"thread_id\":\"test_thread\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc81062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: {'messages': [HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}, id='2aa8111a-39e8-49ad-8868-79c87e029c42'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 2+2\". That\\'s a basic arithmetic question. Let me start by recalling that addition is one of the fundamental operations in mathematics. When you add two numbers together, you\\'re combining their quantities. So 2 plus 2 would be 4. But wait, maybe I should double-check that. Let me count: 2 objects plus another 2 objects make a total of 4 objects. Yes, that seems right.\\n\\nI wonder if there\\'s any context where 2+2 could mean something else. In most everyday situations, it\\'s straightforward addition. But in some specialized fields, like modular arithmetic or different number bases, the result might vary. For example, in base 3, 2+2 would be 11 (which is 4 in decimal). However, unless specified otherwise, the default assumption is base 10. Since the question doesn\\'t mention any specific context, I should stick with the standard interpretation.\\n\\nAnother angle: maybe the user is testing if I know the classic \"2+2=5\" from George Orwell\\'s 1984, which is a metaphor for truth being distorted under totalitarianism. But the user didn\\'t reference that, so probably not. They just want the mathematical answer.\\n\\nI should also consider if there\\'s any trick question here. Sometimes people ask 2+2 as a joke or to see if the responder is paying attention. But again, unless there\\'s a hint of that, it\\'s safe to assume it\\'s a straightforward question.\\n\\nLet me confirm with another method. If I have two apples and someone gives me two more, how many do I have? The answer is four. That\\'s practical, real-world application. So yes, 2+2 equals 4. No contradictions here.\\n\\nI think that\\'s solid. The answer is 4. No need to overcomplicate it unless the user provides more context. But since they didn\\'t, the answer is simple and direct.\\n</think>\\n\\nThe sum of 2 and 2 is **4**. This is a basic arithmetic calculation where adding the two numbers together results in 4. Let me know if you\\'d like to explore other contexts or mathematical concepts!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 14, 'total_tokens': 472, 'completion_time': 1.009650352, 'completion_tokens_details': None, 'prompt_time': 0.000409223, 'prompt_tokens_details': None, 'queue_time': 0.006497916, 'total_time': 1.010059575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-348f-7563-b190-041b338c0004-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 458, 'total_tokens': 472})]}\n",
      "Number of messages: 2\n",
      "Messages: {'messages': [HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}, id='2aa8111a-39e8-49ad-8868-79c87e029c42'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 2+2\". That\\'s a basic arithmetic question. Let me start by recalling that addition is one of the fundamental operations in mathematics. When you add two numbers together, you\\'re combining their quantities. So 2 plus 2 would be 4. But wait, maybe I should double-check that. Let me count: 2 objects plus another 2 objects make a total of 4 objects. Yes, that seems right.\\n\\nI wonder if there\\'s any context where 2+2 could mean something else. In most everyday situations, it\\'s straightforward addition. But in some specialized fields, like modular arithmetic or different number bases, the result might vary. For example, in base 3, 2+2 would be 11 (which is 4 in decimal). However, unless specified otherwise, the default assumption is base 10. Since the question doesn\\'t mention any specific context, I should stick with the standard interpretation.\\n\\nAnother angle: maybe the user is testing if I know the classic \"2+2=5\" from George Orwell\\'s 1984, which is a metaphor for truth being distorted under totalitarianism. But the user didn\\'t reference that, so probably not. They just want the mathematical answer.\\n\\nI should also consider if there\\'s any trick question here. Sometimes people ask 2+2 as a joke or to see if the responder is paying attention. But again, unless there\\'s a hint of that, it\\'s safe to assume it\\'s a straightforward question.\\n\\nLet me confirm with another method. If I have two apples and someone gives me two more, how many do I have? The answer is four. That\\'s practical, real-world application. So yes, 2+2 equals 4. No contradictions here.\\n\\nI think that\\'s solid. The answer is 4. No need to overcomplicate it unless the user provides more context. But since they didn\\'t, the answer is simple and direct.\\n</think>\\n\\nThe sum of 2 and 2 is **4**. This is a basic arithmetic calculation where adding the two numbers together results in 4. Let me know if you\\'d like to explore other contexts or mathematical concepts!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 14, 'total_tokens': 472, 'completion_time': 1.009650352, 'completion_tokens_details': None, 'prompt_time': 0.000409223, 'prompt_tokens_details': None, 'queue_time': 0.006497916, 'total_time': 1.010059575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-348f-7563-b190-041b338c0004-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 458, 'total_tokens': 472}), HumanMessage(content='what is 3+3', additional_kwargs={}, response_metadata={}, id='f46f1b8b-247c-4a50-bcbf-e6058cb267a4'), AIMessage(content='<think>\\nOkay, the user asked \"what is 3+3\". Let me start by recalling that addition is a fundamental arithmetic operation. So, 3 plus 3 is straightforward. The answer should be 6. But wait, maybe the user is testing me or just wants a confirmation. Let me make sure there\\'s no trick here. Sometimes people ask simple questions to check if the AI is paying attention.\\n\\nHmm, the user previously asked about 2+2, and I answered 4. This time it\\'s 3+3. The pattern is consistent. They might be going through basic math problems. I should answer clearly and maybe add a bit more context to be helpful. Let me explain the process of adding 3 and 3. So, 3 is a whole number, adding it to another 3 gives 6. There\\'s no decimal or fraction here, so the result is straightforward. \\n\\nWait, should I consider any other interpretations? Like 3 in a different base? For example, in base 8, 3+3 is 6, which is still 6. Or maybe in modulo arithmetic? But the question doesn\\'t specify, so it\\'s safe to assume base 10. Also, the user might not be familiar with different numeral systems, so keeping it simple is better. \\n\\nAnother thought: the user could be a child learning addition, so using a simple explanation is key. Maybe mention that adding two equal numbers doubles the value. So 3 times 2 is 6. But the question is about addition, not multiplication. Still, drawing the connection might be helpful. \\n\\nI should also check if there\\'s any cultural context or wordplay I\\'m missing. For example, in some contexts, numbers can have symbolic meanings. But in standard math, 3+3 is definitely 6. \\n\\nLet me also think about previous interactions. The user asked \"what is 2+2\" and I answered 4, then asked \"what is 3+3\". The pattern continues, so they might be building up their understanding. Maybe they want to practice more problems. I can offer further assistance by asking if they need more examples. \\n\\nIn summary, the answer is 6. The explanation is straightforward. I should present the answer clearly, confirm the operation, and offer help if they need more problems. That should cover it.\\n</think>\\n\\nThe sum of 3 and 3 is **6**. This is a straightforward addition problem where two instances of the number 3 are combined, resulting in 6. Let me know if you\\'d like to explore more math concepts or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 543, 'prompt_tokens': 75, 'total_tokens': 618, 'completion_time': 1.459860567, 'completion_tokens_details': None, 'prompt_time': 0.00305641, 'prompt_tokens_details': None, 'queue_time': 0.730672928, 'total_time': 1.462916977}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-3962-7263-8cd3-6a00dce042b0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 75, 'output_tokens': 543, 'total_tokens': 618})]}\n",
      "Number of messages: 4\n",
      "Messages: {'messages': [HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}, id='2aa8111a-39e8-49ad-8868-79c87e029c42'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 2+2\". That\\'s a basic arithmetic question. Let me start by recalling that addition is one of the fundamental operations in mathematics. When you add two numbers together, you\\'re combining their quantities. So 2 plus 2 would be 4. But wait, maybe I should double-check that. Let me count: 2 objects plus another 2 objects make a total of 4 objects. Yes, that seems right.\\n\\nI wonder if there\\'s any context where 2+2 could mean something else. In most everyday situations, it\\'s straightforward addition. But in some specialized fields, like modular arithmetic or different number bases, the result might vary. For example, in base 3, 2+2 would be 11 (which is 4 in decimal). However, unless specified otherwise, the default assumption is base 10. Since the question doesn\\'t mention any specific context, I should stick with the standard interpretation.\\n\\nAnother angle: maybe the user is testing if I know the classic \"2+2=5\" from George Orwell\\'s 1984, which is a metaphor for truth being distorted under totalitarianism. But the user didn\\'t reference that, so probably not. They just want the mathematical answer.\\n\\nI should also consider if there\\'s any trick question here. Sometimes people ask 2+2 as a joke or to see if the responder is paying attention. But again, unless there\\'s a hint of that, it\\'s safe to assume it\\'s a straightforward question.\\n\\nLet me confirm with another method. If I have two apples and someone gives me two more, how many do I have? The answer is four. That\\'s practical, real-world application. So yes, 2+2 equals 4. No contradictions here.\\n\\nI think that\\'s solid. The answer is 4. No need to overcomplicate it unless the user provides more context. But since they didn\\'t, the answer is simple and direct.\\n</think>\\n\\nThe sum of 2 and 2 is **4**. This is a basic arithmetic calculation where adding the two numbers together results in 4. Let me know if you\\'d like to explore other contexts or mathematical concepts!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 14, 'total_tokens': 472, 'completion_time': 1.009650352, 'completion_tokens_details': None, 'prompt_time': 0.000409223, 'prompt_tokens_details': None, 'queue_time': 0.006497916, 'total_time': 1.010059575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-348f-7563-b190-041b338c0004-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 458, 'total_tokens': 472}), HumanMessage(content='what is 3+3', additional_kwargs={}, response_metadata={}, id='f46f1b8b-247c-4a50-bcbf-e6058cb267a4'), AIMessage(content='<think>\\nOkay, the user asked \"what is 3+3\". Let me start by recalling that addition is a fundamental arithmetic operation. So, 3 plus 3 is straightforward. The answer should be 6. But wait, maybe the user is testing me or just wants a confirmation. Let me make sure there\\'s no trick here. Sometimes people ask simple questions to check if the AI is paying attention.\\n\\nHmm, the user previously asked about 2+2, and I answered 4. This time it\\'s 3+3. The pattern is consistent. They might be going through basic math problems. I should answer clearly and maybe add a bit more context to be helpful. Let me explain the process of adding 3 and 3. So, 3 is a whole number, adding it to another 3 gives 6. There\\'s no decimal or fraction here, so the result is straightforward. \\n\\nWait, should I consider any other interpretations? Like 3 in a different base? For example, in base 8, 3+3 is 6, which is still 6. Or maybe in modulo arithmetic? But the question doesn\\'t specify, so it\\'s safe to assume base 10. Also, the user might not be familiar with different numeral systems, so keeping it simple is better. \\n\\nAnother thought: the user could be a child learning addition, so using a simple explanation is key. Maybe mention that adding two equal numbers doubles the value. So 3 times 2 is 6. But the question is about addition, not multiplication. Still, drawing the connection might be helpful. \\n\\nI should also check if there\\'s any cultural context or wordplay I\\'m missing. For example, in some contexts, numbers can have symbolic meanings. But in standard math, 3+3 is definitely 6. \\n\\nLet me also think about previous interactions. The user asked \"what is 2+2\" and I answered 4, then asked \"what is 3+3\". The pattern continues, so they might be building up their understanding. Maybe they want to practice more problems. I can offer further assistance by asking if they need more examples. \\n\\nIn summary, the answer is 6. The explanation is straightforward. I should present the answer clearly, confirm the operation, and offer help if they need more problems. That should cover it.\\n</think>\\n\\nThe sum of 3 and 3 is **6**. This is a straightforward addition problem where two instances of the number 3 are combined, resulting in 6. Let me know if you\\'d like to explore more math concepts or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 543, 'prompt_tokens': 75, 'total_tokens': 618, 'completion_time': 1.459860567, 'completion_tokens_details': None, 'prompt_time': 0.00305641, 'prompt_tokens_details': None, 'queue_time': 0.730672928, 'total_time': 1.462916977}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-3962-7263-8cd3-6a00dce042b0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 75, 'output_tokens': 543, 'total_tokens': 618}), HumanMessage(content='what is 4+4', additional_kwargs={}, response_metadata={}, id='f2286d88-3d0e-440d-aad9-5eb001226f88'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 4+4\". Let me recall the pattern here. They\\'ve previously asked about 2+2 and 3+3, so they\\'re probably testing the pattern of adding the same number twice. Each time, I answered with the sum and mentioned it\\'s a basic arithmetic problem.\\n\\nFor 4+4, following the same pattern, the answer should be 8. Let me double-check that. 4 plus 4 equals 8. Yep, that\\'s correct. They might be trying to see if I\\'m consistent or if they can get a trick question. But 4+4 is straightforward. I should present the answer clearly and maybe add a friendly note at the end to keep the interaction positive. Also, since they asked about the previous sums, they might be a student or someone just learning basic math. It\\'s good to reinforce that these are fundamental concepts. Maybe mention that addition is the key here. Alright, ready to respond.\\n</think>\\n\\nThe sum of 4 and 4 is **8**. This is another example of basic addition, where combining two groups of 4 yields 8. Let me know if you\\'d like to dive deeper into math or explore something else! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 145, 'total_tokens': 403, 'completion_time': 0.622549741, 'completion_tokens_details': None, 'prompt_time': 0.005914565, 'prompt_tokens_details': None, 'queue_time': 0.006383829, 'total_time': 0.628464306}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4253-7a11-b691-8453f552f8bf-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 258, 'total_tokens': 403})]}\n",
      "Number of messages: 6\n",
      "Messages: {'messages': [HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}, id='2aa8111a-39e8-49ad-8868-79c87e029c42'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 2+2\". That\\'s a basic arithmetic question. Let me start by recalling that addition is one of the fundamental operations in mathematics. When you add two numbers together, you\\'re combining their quantities. So 2 plus 2 would be 4. But wait, maybe I should double-check that. Let me count: 2 objects plus another 2 objects make a total of 4 objects. Yes, that seems right.\\n\\nI wonder if there\\'s any context where 2+2 could mean something else. In most everyday situations, it\\'s straightforward addition. But in some specialized fields, like modular arithmetic or different number bases, the result might vary. For example, in base 3, 2+2 would be 11 (which is 4 in decimal). However, unless specified otherwise, the default assumption is base 10. Since the question doesn\\'t mention any specific context, I should stick with the standard interpretation.\\n\\nAnother angle: maybe the user is testing if I know the classic \"2+2=5\" from George Orwell\\'s 1984, which is a metaphor for truth being distorted under totalitarianism. But the user didn\\'t reference that, so probably not. They just want the mathematical answer.\\n\\nI should also consider if there\\'s any trick question here. Sometimes people ask 2+2 as a joke or to see if the responder is paying attention. But again, unless there\\'s a hint of that, it\\'s safe to assume it\\'s a straightforward question.\\n\\nLet me confirm with another method. If I have two apples and someone gives me two more, how many do I have? The answer is four. That\\'s practical, real-world application. So yes, 2+2 equals 4. No contradictions here.\\n\\nI think that\\'s solid. The answer is 4. No need to overcomplicate it unless the user provides more context. But since they didn\\'t, the answer is simple and direct.\\n</think>\\n\\nThe sum of 2 and 2 is **4**. This is a basic arithmetic calculation where adding the two numbers together results in 4. Let me know if you\\'d like to explore other contexts or mathematical concepts!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 14, 'total_tokens': 472, 'completion_time': 1.009650352, 'completion_tokens_details': None, 'prompt_time': 0.000409223, 'prompt_tokens_details': None, 'queue_time': 0.006497916, 'total_time': 1.010059575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-348f-7563-b190-041b338c0004-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 458, 'total_tokens': 472}), HumanMessage(content='what is 3+3', additional_kwargs={}, response_metadata={}, id='f46f1b8b-247c-4a50-bcbf-e6058cb267a4'), AIMessage(content='<think>\\nOkay, the user asked \"what is 3+3\". Let me start by recalling that addition is a fundamental arithmetic operation. So, 3 plus 3 is straightforward. The answer should be 6. But wait, maybe the user is testing me or just wants a confirmation. Let me make sure there\\'s no trick here. Sometimes people ask simple questions to check if the AI is paying attention.\\n\\nHmm, the user previously asked about 2+2, and I answered 4. This time it\\'s 3+3. The pattern is consistent. They might be going through basic math problems. I should answer clearly and maybe add a bit more context to be helpful. Let me explain the process of adding 3 and 3. So, 3 is a whole number, adding it to another 3 gives 6. There\\'s no decimal or fraction here, so the result is straightforward. \\n\\nWait, should I consider any other interpretations? Like 3 in a different base? For example, in base 8, 3+3 is 6, which is still 6. Or maybe in modulo arithmetic? But the question doesn\\'t specify, so it\\'s safe to assume base 10. Also, the user might not be familiar with different numeral systems, so keeping it simple is better. \\n\\nAnother thought: the user could be a child learning addition, so using a simple explanation is key. Maybe mention that adding two equal numbers doubles the value. So 3 times 2 is 6. But the question is about addition, not multiplication. Still, drawing the connection might be helpful. \\n\\nI should also check if there\\'s any cultural context or wordplay I\\'m missing. For example, in some contexts, numbers can have symbolic meanings. But in standard math, 3+3 is definitely 6. \\n\\nLet me also think about previous interactions. The user asked \"what is 2+2\" and I answered 4, then asked \"what is 3+3\". The pattern continues, so they might be building up their understanding. Maybe they want to practice more problems. I can offer further assistance by asking if they need more examples. \\n\\nIn summary, the answer is 6. The explanation is straightforward. I should present the answer clearly, confirm the operation, and offer help if they need more problems. That should cover it.\\n</think>\\n\\nThe sum of 3 and 3 is **6**. This is a straightforward addition problem where two instances of the number 3 are combined, resulting in 6. Let me know if you\\'d like to explore more math concepts or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 543, 'prompt_tokens': 75, 'total_tokens': 618, 'completion_time': 1.459860567, 'completion_tokens_details': None, 'prompt_time': 0.00305641, 'prompt_tokens_details': None, 'queue_time': 0.730672928, 'total_time': 1.462916977}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-3962-7263-8cd3-6a00dce042b0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 75, 'output_tokens': 543, 'total_tokens': 618}), HumanMessage(content='what is 4+4', additional_kwargs={}, response_metadata={}, id='f2286d88-3d0e-440d-aad9-5eb001226f88'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 4+4\". Let me recall the pattern here. They\\'ve previously asked about 2+2 and 3+3, so they\\'re probably testing the pattern of adding the same number twice. Each time, I answered with the sum and mentioned it\\'s a basic arithmetic problem.\\n\\nFor 4+4, following the same pattern, the answer should be 8. Let me double-check that. 4 plus 4 equals 8. Yep, that\\'s correct. They might be trying to see if I\\'m consistent or if they can get a trick question. But 4+4 is straightforward. I should present the answer clearly and maybe add a friendly note at the end to keep the interaction positive. Also, since they asked about the previous sums, they might be a student or someone just learning basic math. It\\'s good to reinforce that these are fundamental concepts. Maybe mention that addition is the key here. Alright, ready to respond.\\n</think>\\n\\nThe sum of 4 and 4 is **8**. This is another example of basic addition, where combining two groups of 4 yields 8. Let me know if you\\'d like to dive deeper into math or explore something else! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 145, 'total_tokens': 403, 'completion_time': 0.622549741, 'completion_tokens_details': None, 'prompt_time': 0.005914565, 'prompt_tokens_details': None, 'queue_time': 0.006383829, 'total_time': 0.628464306}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4253-7a11-b691-8453f552f8bf-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 258, 'total_tokens': 403}), HumanMessage(content='what is 5+5', additional_kwargs={}, response_metadata={}, id='1d14c3e2-0496-4b95-b0ac-d39685189129'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the history. They\\'ve asked similar questions before: 2+2, 3+3, 4+4. Each time, I just gave the answer and a brief explanation. Maybe they\\'re testing if I can do basic math, or they\\'re learning addition and need reinforcement.\\n\\nHmm, maybe they want to see a pattern here. The answers so far are 4, 6, 8. Next would be 10. Let me confirm 5+5 is indeed 10. Yep, that\\'s correct. But why are they asking these in sequence? Perhaps they\\'re working through a math problem set or just curious about the pattern. \\n\\nI should keep the response consistent with previous ones. Start with the answer, mention it\\'s basic addition, and offer further help. Maybe add a friendly note to encourage them if they\\'re practicing. Also, check for any deeper needs. If they\\'re struggling with math, I can offer more examples or explain concepts like doubles. But since they haven\\'t asked for that yet, just stick to the pattern. \\n\\nMake sure the answer is clear and concise. No need to overcomplicate. Just state the sum, acknowledge it\\'s straightforward, and keep the door open for more questions. Alright, time to respond.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This is a straightforward addition problem where two instances of the number 5 are combined, resulting in 10. Let me know if you\\'d like to explore patterns in addition or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 212, 'total_tokens': 548, 'completion_time': 0.738393851, 'completion_tokens_details': None, 'prompt_time': 0.00873643, 'prompt_tokens_details': None, 'queue_time': 0.006208331, 'total_time': 0.747130281}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4542-7c71-afc5-640498f6b32d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 212, 'output_tokens': 336, 'total_tokens': 548})]}\n",
      "Number of messages: 8\n",
      "Messages: {'messages': [HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}, id='2aa8111a-39e8-49ad-8868-79c87e029c42'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 2+2\". That\\'s a basic arithmetic question. Let me start by recalling that addition is one of the fundamental operations in mathematics. When you add two numbers together, you\\'re combining their quantities. So 2 plus 2 would be 4. But wait, maybe I should double-check that. Let me count: 2 objects plus another 2 objects make a total of 4 objects. Yes, that seems right.\\n\\nI wonder if there\\'s any context where 2+2 could mean something else. In most everyday situations, it\\'s straightforward addition. But in some specialized fields, like modular arithmetic or different number bases, the result might vary. For example, in base 3, 2+2 would be 11 (which is 4 in decimal). However, unless specified otherwise, the default assumption is base 10. Since the question doesn\\'t mention any specific context, I should stick with the standard interpretation.\\n\\nAnother angle: maybe the user is testing if I know the classic \"2+2=5\" from George Orwell\\'s 1984, which is a metaphor for truth being distorted under totalitarianism. But the user didn\\'t reference that, so probably not. They just want the mathematical answer.\\n\\nI should also consider if there\\'s any trick question here. Sometimes people ask 2+2 as a joke or to see if the responder is paying attention. But again, unless there\\'s a hint of that, it\\'s safe to assume it\\'s a straightforward question.\\n\\nLet me confirm with another method. If I have two apples and someone gives me two more, how many do I have? The answer is four. That\\'s practical, real-world application. So yes, 2+2 equals 4. No contradictions here.\\n\\nI think that\\'s solid. The answer is 4. No need to overcomplicate it unless the user provides more context. But since they didn\\'t, the answer is simple and direct.\\n</think>\\n\\nThe sum of 2 and 2 is **4**. This is a basic arithmetic calculation where adding the two numbers together results in 4. Let me know if you\\'d like to explore other contexts or mathematical concepts!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 14, 'total_tokens': 472, 'completion_time': 1.009650352, 'completion_tokens_details': None, 'prompt_time': 0.000409223, 'prompt_tokens_details': None, 'queue_time': 0.006497916, 'total_time': 1.010059575}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-348f-7563-b190-041b338c0004-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 458, 'total_tokens': 472}), HumanMessage(content='what is 3+3', additional_kwargs={}, response_metadata={}, id='f46f1b8b-247c-4a50-bcbf-e6058cb267a4'), AIMessage(content='<think>\\nOkay, the user asked \"what is 3+3\". Let me start by recalling that addition is a fundamental arithmetic operation. So, 3 plus 3 is straightforward. The answer should be 6. But wait, maybe the user is testing me or just wants a confirmation. Let me make sure there\\'s no trick here. Sometimes people ask simple questions to check if the AI is paying attention.\\n\\nHmm, the user previously asked about 2+2, and I answered 4. This time it\\'s 3+3. The pattern is consistent. They might be going through basic math problems. I should answer clearly and maybe add a bit more context to be helpful. Let me explain the process of adding 3 and 3. So, 3 is a whole number, adding it to another 3 gives 6. There\\'s no decimal or fraction here, so the result is straightforward. \\n\\nWait, should I consider any other interpretations? Like 3 in a different base? For example, in base 8, 3+3 is 6, which is still 6. Or maybe in modulo arithmetic? But the question doesn\\'t specify, so it\\'s safe to assume base 10. Also, the user might not be familiar with different numeral systems, so keeping it simple is better. \\n\\nAnother thought: the user could be a child learning addition, so using a simple explanation is key. Maybe mention that adding two equal numbers doubles the value. So 3 times 2 is 6. But the question is about addition, not multiplication. Still, drawing the connection might be helpful. \\n\\nI should also check if there\\'s any cultural context or wordplay I\\'m missing. For example, in some contexts, numbers can have symbolic meanings. But in standard math, 3+3 is definitely 6. \\n\\nLet me also think about previous interactions. The user asked \"what is 2+2\" and I answered 4, then asked \"what is 3+3\". The pattern continues, so they might be building up their understanding. Maybe they want to practice more problems. I can offer further assistance by asking if they need more examples. \\n\\nIn summary, the answer is 6. The explanation is straightforward. I should present the answer clearly, confirm the operation, and offer help if they need more problems. That should cover it.\\n</think>\\n\\nThe sum of 3 and 3 is **6**. This is a straightforward addition problem where two instances of the number 3 are combined, resulting in 6. Let me know if you\\'d like to explore more math concepts or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 543, 'prompt_tokens': 75, 'total_tokens': 618, 'completion_time': 1.459860567, 'completion_tokens_details': None, 'prompt_time': 0.00305641, 'prompt_tokens_details': None, 'queue_time': 0.730672928, 'total_time': 1.462916977}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-3962-7263-8cd3-6a00dce042b0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 75, 'output_tokens': 543, 'total_tokens': 618}), HumanMessage(content='what is 4+4', additional_kwargs={}, response_metadata={}, id='f2286d88-3d0e-440d-aad9-5eb001226f88'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 4+4\". Let me recall the pattern here. They\\'ve previously asked about 2+2 and 3+3, so they\\'re probably testing the pattern of adding the same number twice. Each time, I answered with the sum and mentioned it\\'s a basic arithmetic problem.\\n\\nFor 4+4, following the same pattern, the answer should be 8. Let me double-check that. 4 plus 4 equals 8. Yep, that\\'s correct. They might be trying to see if I\\'m consistent or if they can get a trick question. But 4+4 is straightforward. I should present the answer clearly and maybe add a friendly note at the end to keep the interaction positive. Also, since they asked about the previous sums, they might be a student or someone just learning basic math. It\\'s good to reinforce that these are fundamental concepts. Maybe mention that addition is the key here. Alright, ready to respond.\\n</think>\\n\\nThe sum of 4 and 4 is **8**. This is another example of basic addition, where combining two groups of 4 yields 8. Let me know if you\\'d like to dive deeper into math or explore something else! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 145, 'total_tokens': 403, 'completion_time': 0.622549741, 'completion_tokens_details': None, 'prompt_time': 0.005914565, 'prompt_tokens_details': None, 'queue_time': 0.006383829, 'total_time': 0.628464306}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4253-7a11-b691-8453f552f8bf-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 145, 'output_tokens': 258, 'total_tokens': 403}), HumanMessage(content='what is 5+5', additional_kwargs={}, response_metadata={}, id='1d14c3e2-0496-4b95-b0ac-d39685189129'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the history. They\\'ve asked similar questions before: 2+2, 3+3, 4+4. Each time, I just gave the answer and a brief explanation. Maybe they\\'re testing if I can do basic math, or they\\'re learning addition and need reinforcement.\\n\\nHmm, maybe they want to see a pattern here. The answers so far are 4, 6, 8. Next would be 10. Let me confirm 5+5 is indeed 10. Yep, that\\'s correct. But why are they asking these in sequence? Perhaps they\\'re working through a math problem set or just curious about the pattern. \\n\\nI should keep the response consistent with previous ones. Start with the answer, mention it\\'s basic addition, and offer further help. Maybe add a friendly note to encourage them if they\\'re practicing. Also, check for any deeper needs. If they\\'re struggling with math, I can offer more examples or explain concepts like doubles. But since they haven\\'t asked for that yet, just stick to the pattern. \\n\\nMake sure the answer is clear and concise. No need to overcomplicate. Just state the sum, acknowledge it\\'s straightforward, and keep the door open for more questions. Alright, time to respond.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This is a straightforward addition problem where two instances of the number 5 are combined, resulting in 10. Let me know if you\\'d like to explore patterns in addition or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 212, 'total_tokens': 548, 'completion_time': 0.738393851, 'completion_tokens_details': None, 'prompt_time': 0.00873643, 'prompt_tokens_details': None, 'queue_time': 0.006208331, 'total_time': 0.747130281}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4542-7c71-afc5-640498f6b32d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 212, 'output_tokens': 336, 'total_tokens': 548}), HumanMessage(content='what is 6+6', additional_kwargs={}, response_metadata={}, id='1698a777-3fca-447b-a100-e9ca4e132a58'), AIMessage(content=\"<think>\\nOkay, the user is asking what 6+6 is. Let me think. They've been asking similar questions starting from 2+2 up to 5+5, and each time I provided the answer and a brief explanation. So the pattern here is they're going through basic addition problems incrementally. \\n\\nFirst, I need to confirm that 6+6 is indeed 12. That's straightforward. But maybe they want a bit more than just the answer. The previous responses included the result, a simple explanation, and an offer to explore further if needed. I should follow the same structure here.\\n\\nWait, maybe I should check if there's a reason behind their questions. Are they a child learning addition? Or someone brushing up on basics? Since the questions are so basic, it's possible they're just starting out. I should keep the explanation clear and friendly, avoiding any complex terms.\\n\\nAlso, the user might be testing if I can handle simple arithmetic, but given the history, they might be genuinely curious or practicing. I should make sure my response is helpful and encouraging. \\n\\nI should mention the sum, explain it briefly, and invite them to ask for more if needed. Maybe add a friendly emoji to keep the tone light. Let me make sure there's no calculation error here. 6 plus 6 is definitely 12. Yep, that's correct. \\n\\nAlright, time to put it all together in a concise and friendly manner.\\n</think>\\n\\nThe sum of 6 and 6 is **12**. This is a basic addition problem where combining two groups of 6 results in 12. Let me know if you'd like to explore more math or dive into patterns (like even numbers doubling!) ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 284, 'total_tokens': 643, 'completion_time': 1.098877742, 'completion_tokens_details': None, 'prompt_time': 0.012925423, 'prompt_tokens_details': None, 'queue_time': 0.007806558, 'total_time': 1.111803165}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-48a5-7891-83d7-135871d7b1c7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 284, 'output_tokens': 359, 'total_tokens': 643})]}\n",
      "Number of messages: 10\n",
      "Messages: {'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the pattern. They\\'ve been asking about 2+2, 3+3, 4+4, and now 5+5. Each time, I\\'ve answered with the sum and mentioned it\\'s a basic arithmetic problem.\\n\\nSo, 5+5 should be 10. Let me confirm. 5 plus 5 equals 10. That\\'s straightforward. They might be testing if I\\'m consistent with the pattern. Also, since they\\'ve been increasing the numbers each time, they might be building up to a larger number or just practicing addition.\\n\\nI should answer clearly, state the answer is 10, and maybe add a friendly note at the end like the previous responses. Also, offer further help in case they need more examples. Let me make sure there\\'s no trick here. The question seems simple, so no need to overcomplicate it. Just the standard answer should suffice.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This follows the same pattern of basic addition where doubling a number results in its sum. Let me know if you\\'d like to explore more examples or other mathematical concepts! ðŸ˜Š', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='0b2349ed-0321-44c6-af01-b8c11797b8fe'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the history. They\\'ve asked similar questions before: 2+2, 3+3, 4+4. Each time, I just gave the answer and a brief explanation. Maybe they\\'re testing if I can do basic math, or they\\'re learning addition and need reinforcement.\\n\\nHmm, maybe they want to see a pattern here. The answers so far are 4, 6, 8. Next would be 10. Let me confirm 5+5 is indeed 10. Yep, that\\'s correct. But why are they asking these in sequence? Perhaps they\\'re working through a math problem set or just curious about the pattern. \\n\\nI should keep the response consistent with previous ones. Start with the answer, mention it\\'s basic addition, and offer further help. Maybe add a friendly note to encourage them if they\\'re practicing. Also, check for any deeper needs. If they\\'re struggling with math, I can offer more examples or explain concepts like doubles. But since they haven\\'t asked for that yet, just stick to the pattern. \\n\\nMake sure the answer is clear and concise. No need to overcomplicate. Just state the sum, acknowledge it\\'s straightforward, and keep the door open for more questions. Alright, time to respond.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This is a straightforward addition problem where two instances of the number 5 are combined, resulting in 10. Let me know if you\\'d like to explore patterns in addition or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 212, 'total_tokens': 548, 'completion_time': 0.738393851, 'completion_tokens_details': None, 'prompt_time': 0.00873643, 'prompt_tokens_details': None, 'queue_time': 0.006208331, 'total_time': 0.747130281}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4542-7c71-afc5-640498f6b32d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 212, 'output_tokens': 336, 'total_tokens': 548}), HumanMessage(content='what is 6+6', additional_kwargs={}, response_metadata={}, id='1698a777-3fca-447b-a100-e9ca4e132a58'), AIMessage(content=\"<think>\\nOkay, the user is asking what 6+6 is. Let me think. They've been asking similar questions starting from 2+2 up to 5+5, and each time I provided the answer and a brief explanation. So the pattern here is they're going through basic addition problems incrementally. \\n\\nFirst, I need to confirm that 6+6 is indeed 12. That's straightforward. But maybe they want a bit more than just the answer. The previous responses included the result, a simple explanation, and an offer to explore further if needed. I should follow the same structure here.\\n\\nWait, maybe I should check if there's a reason behind their questions. Are they a child learning addition? Or someone brushing up on basics? Since the questions are so basic, it's possible they're just starting out. I should keep the explanation clear and friendly, avoiding any complex terms.\\n\\nAlso, the user might be testing if I can handle simple arithmetic, but given the history, they might be genuinely curious or practicing. I should make sure my response is helpful and encouraging. \\n\\nI should mention the sum, explain it briefly, and invite them to ask for more if needed. Maybe add a friendly emoji to keep the tone light. Let me make sure there's no calculation error here. 6 plus 6 is definitely 12. Yep, that's correct. \\n\\nAlright, time to put it all together in a concise and friendly manner.\\n</think>\\n\\nThe sum of 6 and 6 is **12**. This is a basic addition problem where combining two groups of 6 results in 12. Let me know if you'd like to explore more math or dive into patterns (like even numbers doubling!) ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 284, 'total_tokens': 643, 'completion_time': 1.098877742, 'completion_tokens_details': None, 'prompt_time': 0.012925423, 'prompt_tokens_details': None, 'queue_time': 0.007806558, 'total_time': 1.111803165}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-48a5-7891-83d7-135871d7b1c7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 284, 'output_tokens': 359, 'total_tokens': 643}), HumanMessage(content='what is 7+7', additional_kwargs={}, response_metadata={}, id='f317b51d-7e1b-4c05-aec6-a7be311c9129'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 7+7\". Let me see. They\\'ve been going through a series of doubling numbers: started with 2+2, then 3+3, 4+4, 5+5, 6+6, and now 7+7. Each time, I\\'ve answered with the sum and added a friendly note about patterns or further help.\\n\\nSo for 7+7, the answer should be 14. Let me confirm that. 7 plus 7 is indeed 14. The pattern here is consistent: doubling each number gives an even result. Maybe the user is trying to understand the concept of doubling or even numbers. \\n\\nThey might also be building up to test if I can keep up with the sequence or if there\\'s a trick. But the question is straightforward. I should answer clearly, state the answer, and perhaps mention the pattern again. Also, keep the tone friendly and offer further assistance. \\n\\nI should make sure not to overcomplicate it. Just a simple response with the answer and a note about the doubling pattern. Maybe add an emoji to keep it light. Let me check previous responses for consistency. Yep, they all follow the same structure. Alright, that should work.\\n</think>\\n\\nThe sum of 7 and 7 is **14**. This is a classic example of doubling, where adding a number to itself results in twice its value. Let me know if you\\'d like to explore more patterns or tackle bigger numbers! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 418, 'total_tokens': 735, 'completion_time': 1.145709851, 'completion_tokens_details': None, 'prompt_time': 0.017779755, 'prompt_tokens_details': None, 'queue_time': 0.006740897, 'total_time': 1.163489606}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-5087-7291-be37-fadeeb9bce35-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 418, 'output_tokens': 317, 'total_tokens': 735})]}\n",
      "Number of messages: 6\n",
      "Messages: {'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the pattern. They\\'ve been asking about 2+2, 3+3, 4+4, and now 5+5. Each time, I\\'ve answered with the sum and mentioned it\\'s a basic arithmetic problem.\\n\\nSo, 5+5 should be 10. Let me confirm. 5 plus 5 equals 10. That\\'s straightforward. They might be testing if I\\'m consistent with the pattern. Also, since they\\'ve been increasing the numbers each time, they might be building up to a larger number or just practicing addition.\\n\\nI should answer clearly, state the answer is 10, and maybe add a friendly note at the end like the previous responses. Also, offer further help in case they need more examples. Let me make sure there\\'s no trick here. The question seems simple, so no need to overcomplicate it. Just the standard answer should suffice.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This follows the same pattern of basic addition where doubling a number results in its sum. Let me know if you\\'d like to explore more examples or other mathematical concepts! ðŸ˜Š', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='0b2349ed-0321-44c6-af01-b8c11797b8fe'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 5+5\". Let me check the history. They\\'ve asked similar questions before: 2+2, 3+3, 4+4. Each time, I just gave the answer and a brief explanation. Maybe they\\'re testing if I can do basic math, or they\\'re learning addition and need reinforcement.\\n\\nHmm, maybe they want to see a pattern here. The answers so far are 4, 6, 8. Next would be 10. Let me confirm 5+5 is indeed 10. Yep, that\\'s correct. But why are they asking these in sequence? Perhaps they\\'re working through a math problem set or just curious about the pattern. \\n\\nI should keep the response consistent with previous ones. Start with the answer, mention it\\'s basic addition, and offer further help. Maybe add a friendly note to encourage them if they\\'re practicing. Also, check for any deeper needs. If they\\'re struggling with math, I can offer more examples or explain concepts like doubles. But since they haven\\'t asked for that yet, just stick to the pattern. \\n\\nMake sure the answer is clear and concise. No need to overcomplicate. Just state the sum, acknowledge it\\'s straightforward, and keep the door open for more questions. Alright, time to respond.\\n</think>\\n\\nThe sum of 5 and 5 is **10**. This is a straightforward addition problem where two instances of the number 5 are combined, resulting in 10. Let me know if you\\'d like to explore patterns in addition or need further clarification! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 212, 'total_tokens': 548, 'completion_time': 0.738393851, 'completion_tokens_details': None, 'prompt_time': 0.00873643, 'prompt_tokens_details': None, 'queue_time': 0.006208331, 'total_time': 0.747130281}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-4542-7c71-afc5-640498f6b32d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 212, 'output_tokens': 336, 'total_tokens': 548}), HumanMessage(content='what is 6+6', additional_kwargs={}, response_metadata={}, id='1698a777-3fca-447b-a100-e9ca4e132a58'), AIMessage(content=\"<think>\\nOkay, the user is asking what 6+6 is. Let me think. They've been asking similar questions starting from 2+2 up to 5+5, and each time I provided the answer and a brief explanation. So the pattern here is they're going through basic addition problems incrementally. \\n\\nFirst, I need to confirm that 6+6 is indeed 12. That's straightforward. But maybe they want a bit more than just the answer. The previous responses included the result, a simple explanation, and an offer to explore further if needed. I should follow the same structure here.\\n\\nWait, maybe I should check if there's a reason behind their questions. Are they a child learning addition? Or someone brushing up on basics? Since the questions are so basic, it's possible they're just starting out. I should keep the explanation clear and friendly, avoiding any complex terms.\\n\\nAlso, the user might be testing if I can handle simple arithmetic, but given the history, they might be genuinely curious or practicing. I should make sure my response is helpful and encouraging. \\n\\nI should mention the sum, explain it briefly, and invite them to ask for more if needed. Maybe add a friendly emoji to keep the tone light. Let me make sure there's no calculation error here. 6 plus 6 is definitely 12. Yep, that's correct. \\n\\nAlright, time to put it all together in a concise and friendly manner.\\n</think>\\n\\nThe sum of 6 and 6 is **12**. This is a basic addition problem where combining two groups of 6 results in 12. Let me know if you'd like to explore more math or dive into patterns (like even numbers doubling!) ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 284, 'total_tokens': 643, 'completion_time': 1.098877742, 'completion_tokens_details': None, 'prompt_time': 0.012925423, 'prompt_tokens_details': None, 'queue_time': 0.007806558, 'total_time': 1.111803165}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-48a5-7891-83d7-135871d7b1c7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 284, 'output_tokens': 359, 'total_tokens': 643}), HumanMessage(content='what is 7+7', additional_kwargs={}, response_metadata={}, id='f317b51d-7e1b-4c05-aec6-a7be311c9129'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 7+7\". Let me see. They\\'ve been going through a series of doubling numbers: started with 2+2, then 3+3, 4+4, 5+5, 6+6, and now 7+7. Each time, I\\'ve answered with the sum and added a friendly note about patterns or further help.\\n\\nSo for 7+7, the answer should be 14. Let me confirm that. 7 plus 7 is indeed 14. The pattern here is consistent: doubling each number gives an even result. Maybe the user is trying to understand the concept of doubling or even numbers. \\n\\nThey might also be building up to test if I can keep up with the sequence or if there\\'s a trick. But the question is straightforward. I should answer clearly, state the answer, and perhaps mention the pattern again. Also, keep the tone friendly and offer further assistance. \\n\\nI should make sure not to overcomplicate it. Just a simple response with the answer and a note about the doubling pattern. Maybe add an emoji to keep it light. Let me check previous responses for consistency. Yep, they all follow the same structure. Alright, that should work.\\n</think>\\n\\nThe sum of 7 and 7 is **14**. This is a classic example of doubling, where adding a number to itself results in twice its value. Let me know if you\\'d like to explore more patterns or tackle bigger numbers! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 317, 'prompt_tokens': 418, 'total_tokens': 735, 'completion_time': 1.145709851, 'completion_tokens_details': None, 'prompt_time': 0.017779755, 'prompt_tokens_details': None, 'queue_time': 0.006740897, 'total_time': 1.163489606}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-5087-7291-be37-fadeeb9bce35-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 418, 'output_tokens': 317, 'total_tokens': 735}), HumanMessage(content='what is 8+8', additional_kwargs={}, response_metadata={}, id='b6cd0ed5-5bff-4b5a-83a7-39f7e66298ab'), AIMessage(content='<think>\\nOkay, the user is asking \"what is 8+8\". Let me see. They\\'ve been asking similar questions like 5+5, 6+6, 7+7, and now 8+8. Each time, I\\'ve given the answer and mentioned it\\'s a doubling problem. The pattern is clearâ€”they\\'re learning basic addition, maybe testing consistency, or building up to larger numbers.\\n\\nI need to confirm the answer first. 8+8 is 16. That\\'s straightforward. Now, the user\\'s history shows they like the pattern of doubling. So, I should follow the same structure: state the answer, mention it\\'s a doubling example, and offer further help. Also, adding a friendly emoji to keep the tone positive. Let me make sure there\\'s no trick here. No, it\\'s just a simple addition. Alright, respond with the answer and a cheerful note.\\n</think>\\n\\nThe sum of 8 and 8 is **16**. This is another example of doubling, where adding a number to itself gives twice its value. Ready for the next one? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 231, 'prompt_tokens': 486, 'total_tokens': 717, 'completion_time': 0.440486454, 'completion_tokens_details': None, 'prompt_time': 0.037545707, 'prompt_tokens_details': None, 'queue_time': 0.193939295, 'total_time': 0.478032161}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_78ac7f3229', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d8f-558a-71b2-b0c1-4c74ea1db07d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 486, 'output_tokens': 231, 'total_tokens': 717})]}\n",
      "Number of messages: 8\n"
     ]
    }
   ],
   "source": [
    "question = [\n",
    "    \"what is 2+2\",\n",
    "    \"what is 3+3\",\n",
    "    \"what is 4+4\",\n",
    "    \"what is 5+5\",\n",
    "    \"what is 6+6\",\n",
    "    \"what is 7+7\",\n",
    "    \"what is 8+8\",\n",
    "    # \"what is 9+9\",\n",
    "]\n",
    "for q in question:\n",
    "    response = agent.invoke({\"messages\" : [HumanMessage(content=q)]},config)\n",
    "    print(f\"Messages: {response}\")\n",
    "    print(f\"Number of messages: {len(response['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c071e",
   "metadata": {},
   "source": [
    "### Token Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60d50130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "@tool\n",
    "def search_hotel(city:str) -> str:\n",
    "    \"\"\"\"Search for hotels in a city and return the results as a string.\"\"\"\n",
    "    # In a real implementation, this function would call an external API to search for hotels.\n",
    "    # For this example, we'll just return a hardcoded string.\n",
    "    return f\"\"\"Hotels in city : {city}:\n",
    "    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\n",
    "    2. Hotel D\\n3. Hotel E.\n",
    "    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\n",
    "    \"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model = 'groq:qwen/qwen3-32b',\n",
    "    tools = [search_hotel],\n",
    "    checkpointer = InMemorySaver(),\n",
    "    middleware = [SummarizationMiddleware(\n",
    "        model = 'groq:qwen/qwen3-32b',\n",
    "        trigger = (\"tokens\",550),\n",
    "        keep = (\"tokens\",200),\n",
    "    ),\n",
    "    ]\n",
    ")\n",
    "config = {\"configurable\":{\"thread_id\":\"test_thread\"}}\n",
    "\n",
    "def count_tokesn(messages):\n",
    "    total = sum(len(str(m.content)) for m in messages)\n",
    "    return total // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93000af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York - Tokens: 102 tokens,4 messages\n",
      "[HumanMessage(content='Search for hotels in New York', additional_kwargs={}, response_metadata={}, id='3a773193-bd39-496b-afdc-3f6df7200327'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user wants to search for hotels in New York. Let me check the available tools. There\\'s a function called search_hotel that takes a city parameter. The required parameter is city, and it\\'s a string. Since the user specified New York, I need to call this function with \"New York\" as the city argument. I\\'ll make sure to format the tool call correctly within the XML tags as specified.\\n', 'tool_calls': [{'id': '8pbpj483n', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 160, 'total_tokens': 272, 'completion_time': 0.165327871, 'completion_tokens_details': {'reasoning_tokens': 86}, 'prompt_time': 0.006561001, 'prompt_tokens_details': None, 'queue_time': 0.006226614, 'total_time': 0.171888872}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-8be0-7230-a0f8-8573305b62b2-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'New York'}, 'id': '8pbpj483n', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 160, 'output_tokens': 112, 'total_tokens': 272, 'output_token_details': {'reasoning': 86}}), ToolMessage(content='Hotels in city : New York:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='cc74385c-c06d-4f5c-9c58-ac9137e04f25', tool_call_id='8pbpj483n'), AIMessage(content='Here are the hotels in New York from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, let me try to figure out how to handle this. The user asked to search for hotels in New York, and the tool response came back with a list. The response seems a bit formatted oddly, with some numbering issues, but I can parse through it.\\n\\nFirst, I need to present the hotels in a clear way. Let me list them out properly. The tool mentioned Hotel A, B, C, D, E, F, G, H. Even though the numbering is messed up, I can just list them as a numbered list without the subpoints. Maybe the user just wants a straightforward list of options. I should also ask if they need more details or help booking. Keep the response friendly and helpful. Make sure there are no markdown formats, just plain text. Let me check again to ensure all hotels are included and the formatting is correct.\\n'}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 249, 'total_tokens': 496, 'completion_time': 1.2784488010000001, 'completion_tokens_details': {'reasoning_tokens': 175}, 'prompt_time': 0.010731995, 'prompt_tokens_details': None, 'queue_time': 0.235178028, 'total_time': 1.2891807960000001}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-8d96-7a22-a32e-88259db62ef6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 249, 'output_tokens': 247, 'total_tokens': 496, 'output_token_details': {'reasoning': 175}})]\n",
      "Los Angeles - Tokens: 206 tokens,8 messages\n",
      "[HumanMessage(content='Search for hotels in New York', additional_kwargs={}, response_metadata={}, id='3a773193-bd39-496b-afdc-3f6df7200327'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user wants to search for hotels in New York. Let me check the available tools. There\\'s a function called search_hotel that takes a city parameter. The required parameter is city, and it\\'s a string. Since the user specified New York, I need to call this function with \"New York\" as the city argument. I\\'ll make sure to format the tool call correctly within the XML tags as specified.\\n', 'tool_calls': [{'id': '8pbpj483n', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 160, 'total_tokens': 272, 'completion_time': 0.165327871, 'completion_tokens_details': {'reasoning_tokens': 86}, 'prompt_time': 0.006561001, 'prompt_tokens_details': None, 'queue_time': 0.006226614, 'total_time': 0.171888872}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-8be0-7230-a0f8-8573305b62b2-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'New York'}, 'id': '8pbpj483n', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 160, 'output_tokens': 112, 'total_tokens': 272, 'output_token_details': {'reasoning': 86}}), ToolMessage(content='Hotels in city : New York:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='cc74385c-c06d-4f5c-9c58-ac9137e04f25', tool_call_id='8pbpj483n'), AIMessage(content='Here are the hotels in New York from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, let me try to figure out how to handle this. The user asked to search for hotels in New York, and the tool response came back with a list. The response seems a bit formatted oddly, with some numbering issues, but I can parse through it.\\n\\nFirst, I need to present the hotels in a clear way. Let me list them out properly. The tool mentioned Hotel A, B, C, D, E, F, G, H. Even though the numbering is messed up, I can just list them as a numbered list without the subpoints. Maybe the user just wants a straightforward list of options. I should also ask if they need more details or help booking. Keep the response friendly and helpful. Make sure there are no markdown formats, just plain text. Let me check again to ensure all hotels are included and the formatting is correct.\\n'}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 249, 'total_tokens': 496, 'completion_time': 1.2784488010000001, 'completion_tokens_details': {'reasoning_tokens': 175}, 'prompt_time': 0.010731995, 'prompt_tokens_details': None, 'queue_time': 0.235178028, 'total_time': 1.2891807960000001}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-8d96-7a22-a32e-88259db62ef6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 249, 'output_tokens': 247, 'total_tokens': 496, 'output_token_details': {'reasoning': 175}}), HumanMessage(content='Search for hotels in Los Angeles', additional_kwargs={}, response_metadata={}, id='18737b50-9994-4b1d-b2ed-a15729970d35'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user asked to search for hotels in Los Angeles. Let me check the tools available. There\\'s the search_hotel function that takes a city parameter. The previous interaction was about New York, and the user got a list of hotels. Now they want the same for Los Angeles.\\n\\nI need to call the search_hotel function again with the city set to \"Los Angeles\". The function doesn\\'t return actual data, but the previous response had a formatted list. I should make sure to structure the tool call correctly, using the exact function name and parameter. No other parameters are needed since the tool only requires the city. Let me verify the JSON format to avoid errors. Once the tool responds, I can present the hotels in the same list format as before. Alright, ready to send the tool call.\\n', 'tool_calls': [{'id': 'vb9v09wp6', 'function': {'arguments': '{\"city\":\"Los Angeles\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 332, 'total_tokens': 522, 'completion_time': 0.350045108, 'completion_tokens_details': {'reasoning_tokens': 164}, 'prompt_time': 0.016389791, 'prompt_tokens_details': None, 'queue_time': 0.007461498, 'total_time': 0.366434899}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-93ed-7892-be75-6b4c6c2defb2-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'Los Angeles'}, 'id': 'vb9v09wp6', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 332, 'output_tokens': 190, 'total_tokens': 522, 'output_token_details': {'reasoning': 164}}), ToolMessage(content='Hotels in city : Los Angeles:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='f86a8a6f-fd86-43f1-b753-a8838321f231', tool_call_id='vb9v09wp6'), AIMessage(content='Here are the hotels in Los Angeles from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, the user asked for hotels in Los Angeles. I need to process the tool response they provided. Let me look at the response first. The structure seems similar to the previous New York search. There\\'s a list of hotels under \"Hotels in city : Los Angeles:\".\\n\\nStarting with the first entry: \"1. Hotel A\". That\\'s straightforward. Then \"2. Hotel B\", \"3. Hotel C.\" with a period at the end. Next line starts with \"    2. Hotel D\" which seems like a sublist under the previous entry maybe? But the numbering is off. Then \"3. Hotel E.\" again with a period. Then another line \"    3. Hotel F\" followed by \"4. Hotel G\" and \"5. Hotel H.\" with periods again. The indentation might indicate subpoints, but the numbering isn\\'t consistent. \\n\\nI need to parse this into a clean list. Maybe the main list is numbered 1 to 5, and the indented ones are subpoints. But the user might just want a flat list. Let me check the previous response. For New York, the assistant listed them as 1 to 8, even though the tool response had nested numbers. So perhaps the assistant combined all entries into a single list, ignoring the subpoints. \\n\\nIn the Los Angeles response, the same pattern is present. The tool\\'s response has a mix of numbered lines and indented numbers. The assistant should probably merge all into a single numbered list. Let me count the entries. Hotel A (1), B (2), C (3), D (4?), but the next is 2. Hotel D which might be a typo. Wait, maybe the original tool response had some formatting issues. The user might have intended the numbers to be sequential but there are repeated numbers with indents. \\n\\nSo, for clarity, the assistant should list all unique hotels in order, numbering them sequentially without the subpoints. So Hotel A is 1, B 2, C 3, D 4, E 5, F 6, G 7, H 8. That matches the previous approach. The user probably wants a clean list without the nested numbers. I\\'ll format it that way and offer further assistance.\\n'}, response_metadata={'token_usage': {'completion_tokens': 537, 'prompt_tokens': 421, 'total_tokens': 958, 'completion_time': 1.9149778880000001, 'completion_tokens_details': {'reasoning_tokens': 465}, 'prompt_time': 0.019604222, 'prompt_tokens_details': None, 'queue_time': 0.007055369, 'total_time': 1.93458211}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-95fc-7912-9929-7cb8be430a87-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 421, 'output_tokens': 537, 'total_tokens': 958, 'output_token_details': {'reasoning': 465}})]\n",
      "Chicago - Tokens: 1054 tokens,8 messages\n",
      "[HumanMessage(content=\"Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let me try to work through this step by step. The user wants me to extract the most relevant context from their conversation history. The messages provided are a summary of the conversation so far, which includes a previous search for hotels in New York and now a new request to search for hotels in Los Angeles.\\n\\nFirst, I need to identify the SESSION INTENT. The user's primary goal here is to search for hotels in Los Angeles. The previous interaction was about New York, but the latest message is a new query for LA. So the intent is clear.\\n\\nNext, the SUMMARY section. I need to highlight the key points: the user first asked for New York hotels, which were provided, and now they're switching to Los Angeles. The assistant should note that the previous search results for New York are no longer relevant and focus on the new request. Also, since the user hasn't selected a hotel yet, the next step is to perform the search for LA.\\n\\nFor ARTIFACTS, the previous tool call for New York and its results are part of the conversation history but might not be needed now. However, since the user is changing the location, the current step is to issue a new tool call for Los Angeles. So the artifacts would include the new tool call for LA and the upcoming results once they're retrieved.\\n\\nIn NEXT STEPS, the immediate action is to execute the search for Los Angeles hotels. After that, the assistant should present the results and offer further assistance similar to the previous interaction. The user might want details about specific hotels or proceed with booking, so the next steps should reflect that possibility.\\n\\nI need to make sure I don't include outdated information from the New York search in the summary. The focus is on the current request for Los Angeles. Also, check if there are any rejected options, but in this case, the user hasn't provided any alternatives, just a new location. \\n\\nWait, the user's latest message is a new query. The previous summary mentioned the New York search, but the current task is to handle the Los Angeles request. So the summary should reflect that the user has shifted the location, and the assistant needs to address that. The artifacts should include the new tool call for LA, not the previous one. That makes sense.\\n\\nAlso, the NEXT STEPS should be clear: perform the search, present results, and offer follow-up options. The user might not have selected a hotel yet, so the assistant should be ready to assist with the next steps after the search results are available.\\n</think>\\n\\n## SESSION INTENT  \\nThe user's primary goal is to search for hotels in Los Angeles and receive assistance with booking or additional details.  \\n\\n## SUMMARY  \\n- Previously, a hotel search was conducted for New York, yielding 8 results (Hotel Aâ€“Hotel H).  \\n- The user has now shifted the location to Los Angeles for a new hotel search.  \\n- No specific preferences or selections have been made for the Los Angeles search.  \\n\\n## ARTIFACTS  \\n- **Tool Call:** `{'name': 'search_hotel', 'args': {'city': 'Los Angeles'}, 'id': 'new_tool_call_id', 'type': 'tool_call'}`  \\n- **Search Results:** Pending (waiting for tool response).  \\n\\n## NEXT STEPS  \\n- Execute the `search_hotel` tool call for Los Angeles.  \\n- Present the results to the user once available.  \\n- Offer follow-up assistance (e.g., details, booking) if a specific hotel is selected.\", additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='f7065701-c1d4-4f6c-9062-8b0aa084af89'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user asked to search for hotels in Los Angeles. Let me check the tools available. There\\'s the search_hotel function that takes a city parameter. The previous interaction was about New York, and the user got a list of hotels. Now they want the same for Los Angeles.\\n\\nI need to call the search_hotel function again with the city set to \"Los Angeles\". The function doesn\\'t return actual data, but the previous response had a formatted list. I should make sure to structure the tool call correctly, using the exact function name and parameter. No other parameters are needed since the tool only requires the city. Let me verify the JSON format to avoid errors. Once the tool responds, I can present the hotels in the same list format as before. Alright, ready to send the tool call.\\n', 'tool_calls': [{'id': 'vb9v09wp6', 'function': {'arguments': '{\"city\":\"Los Angeles\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 332, 'total_tokens': 522, 'completion_time': 0.350045108, 'completion_tokens_details': {'reasoning_tokens': 164}, 'prompt_time': 0.016389791, 'prompt_tokens_details': None, 'queue_time': 0.007461498, 'total_time': 0.366434899}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-93ed-7892-be75-6b4c6c2defb2-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'Los Angeles'}, 'id': 'vb9v09wp6', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 332, 'output_tokens': 190, 'total_tokens': 522, 'output_token_details': {'reasoning': 164}}), ToolMessage(content='Hotels in city : Los Angeles:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='f86a8a6f-fd86-43f1-b753-a8838321f231', tool_call_id='vb9v09wp6'), AIMessage(content='Here are the hotels in Los Angeles from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, the user asked for hotels in Los Angeles. I need to process the tool response they provided. Let me look at the response first. The structure seems similar to the previous New York search. There\\'s a list of hotels under \"Hotels in city : Los Angeles:\".\\n\\nStarting with the first entry: \"1. Hotel A\". That\\'s straightforward. Then \"2. Hotel B\", \"3. Hotel C.\" with a period at the end. Next line starts with \"    2. Hotel D\" which seems like a sublist under the previous entry maybe? But the numbering is off. Then \"3. Hotel E.\" again with a period. Then another line \"    3. Hotel F\" followed by \"4. Hotel G\" and \"5. Hotel H.\" with periods again. The indentation might indicate subpoints, but the numbering isn\\'t consistent. \\n\\nI need to parse this into a clean list. Maybe the main list is numbered 1 to 5, and the indented ones are subpoints. But the user might just want a flat list. Let me check the previous response. For New York, the assistant listed them as 1 to 8, even though the tool response had nested numbers. So perhaps the assistant combined all entries into a single list, ignoring the subpoints. \\n\\nIn the Los Angeles response, the same pattern is present. The tool\\'s response has a mix of numbered lines and indented numbers. The assistant should probably merge all into a single numbered list. Let me count the entries. Hotel A (1), B (2), C (3), D (4?), but the next is 2. Hotel D which might be a typo. Wait, maybe the original tool response had some formatting issues. The user might have intended the numbers to be sequential but there are repeated numbers with indents. \\n\\nSo, for clarity, the assistant should list all unique hotels in order, numbering them sequentially without the subpoints. So Hotel A is 1, B 2, C 3, D 4, E 5, F 6, G 7, H 8. That matches the previous approach. The user probably wants a clean list without the nested numbers. I\\'ll format it that way and offer further assistance.\\n'}, response_metadata={'token_usage': {'completion_tokens': 537, 'prompt_tokens': 421, 'total_tokens': 958, 'completion_time': 1.9149778880000001, 'completion_tokens_details': {'reasoning_tokens': 465}, 'prompt_time': 0.019604222, 'prompt_tokens_details': None, 'queue_time': 0.007055369, 'total_time': 1.93458211}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-95fc-7912-9929-7cb8be430a87-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 421, 'output_tokens': 537, 'total_tokens': 958, 'output_token_details': {'reasoning': 465}}), HumanMessage(content='Search for hotels in Chicago', additional_kwargs={}, response_metadata={}, id='f03228fe-1f9a-40c3-987a-0584c7d8907d'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user wants to search for hotels in Chicago. Let me check the tools provided. There\\'s a function called search_hotel that takes a city parameter. The previous interactions show that when the user asked for New York and Los Angeles, the assistant called the search_hotel function with the respective city names. The response format includes a list of hotels, even though the tool response had some formatting issues, like inconsistent numbering. The assistant corrected that by listing them as 1 to 8.\\n\\nSo, for Chicago, I should follow the same pattern. First, call the search_hotel function with \"Chicago\" as the city. The user probably expects a list of hotels in Chicago, similar to the previous responses. Even if the tool\\'s raw response has formatting issues, the assistant should present the hotels in a clear, numbered list. The user might then ask for more details or booking help, but the immediate step is to provide the list. I need to make sure the function call is correctly formatted in JSON within the tool_call tags. No other functions are available, so this is the only action needed here.\\n', 'tool_calls': [{'id': 'n9qkkvprh', 'function': {'arguments': '{\"city\":\"Chicago\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 1030, 'total_tokens': 1280, 'completion_time': 0.531305441, 'completion_tokens_details': {'reasoning_tokens': 225}, 'prompt_time': 0.04741441, 'prompt_tokens_details': None, 'queue_time': 0.007331851, 'total_time': 0.578719851}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-a4b3-7a83-88c8-479f19b23e68-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'Chicago'}, 'id': 'n9qkkvprh', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1030, 'output_tokens': 250, 'total_tokens': 1280, 'output_token_details': {'reasoning': 225}}), ToolMessage(content='Hotels in city : Chicago:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='e03c526e-00e8-4c6c-8af4-562141fde3ea', tool_call_id='n9qkkvprh'), AIMessage(content='Here are the hotels in Chicago from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, the user asked for hotels in Chicago after previously searching for Los Angeles and New York. Let me check the pattern here. Each time they request a new city, I need to call the search_hotel function with that city\\'s name. The tool response format seems consistent, listing hotels in a numbered list with some indentation issues. \\n\\nThe user\\'s current query is \"Search for hotels in Chicago,\" so the immediate step is to invoke the search_hotel function again with \"Chicago\" as the city parameter. The previous responses from the tool have a similar structure, so I should expect the same here. Once the tool returns the list, I\\'ll need to present it in a user-friendly way, maybe fixing the formatting so the list is clear.\\n\\nWait, in the last interaction, after the tool response, I listed the hotels in a simple numbered list without the subpoints. The user might appreciate that format. So I\\'ll take the tool\\'s response for Chicago, parse the hotels, and present them neatly. Also, I should offer further assistance, like details or booking help, just like before. Let me make sure there\\'s no duplication or confusion in the list. Hotels A to H again? Maybe the tool uses the same names, but the user might not care as long as the options are clear. Alright, proceed to format the response and ask if they need more info.\\n'}, response_metadata={'token_usage': {'completion_tokens': 350, 'prompt_tokens': 1141, 'total_tokens': 1491, 'completion_time': 0.818370383, 'completion_tokens_details': {'reasoning_tokens': 279}, 'prompt_time': 0.049601736, 'prompt_tokens_details': None, 'queue_time': 0.006294784, 'total_time': 0.867972119}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-fd97-7091-aef1-e1f5b963572b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1141, 'output_tokens': 350, 'total_tokens': 1491, 'output_token_details': {'reasoning': 279}})]\n",
      "Houston - Tokens: 1051 tokens,8 messages\n",
      "[HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let me try to figure out what the user needs here. They provided a conversation history where the assistant first searched for hotels in New York, then the user asked for Los Angeles. The assistant made a tool call for LA and got the results. Now, the user is asking to search for hotels in Chicago.\\n\\nFirst, I need to extract the session intent. The user\\'s main goal seems to be finding hotels in Chicago now. The previous searches for New York and Los Angeles are part of the history but the current focus is on Chicago.\\n\\nIn the summary section, I should note the transition from LA to Chicago. The user shifted the search location again. The previous LA search was completed, and the user hasn\\'t selected a hotel yet. Now, a new search for Chicago is requested. The assistant needs to process this new query.\\n\\nArtifacts would include the new tool call for Chicago. The previous LA tool call and results are still part of the history but the current action is the Chicago search. The LA results are pending a user decision, but the user hasn\\'t acted on them yet. \\n\\nNext steps: The assistant needs to execute the Chicago hotel search. Once the results are available, the user might need to choose a hotel or request more info. The assistant should wait for the user\\'s response after the search is done.\\n\\nWait, the user\\'s latest message is \"Search for hotels in Chicago.\" So the assistant needs to make a tool call for Chicago. The previous LA results are still there, but the user is moving on to a new city. The session intent is now Chicago. The summary should reflect the shift from LA to Chicago, mentioning the previous LA search but focusing on the new Chicago request. \\n\\nI should structure the summary to show the progression: New York search completed, LA search completed with results, now moving to Chicago. The artifacts need to list the new tool call for Chicago. The next step is to perform the Chicago search and present results, then prompt the user for their choice or further actions. The user hasn\\'t responded to the LA results yet, but they\\'ve moved on to Chicago, so maybe the LA results are still pending but the focus is now on Chicago.\\n</think>\\n\\n## SESSION INTENT  \\nThe user\\'s primary goal is to identify a hotel in Chicago, building on prior hotel searches for New York and Los Angeles.  \\n\\n## SUMMARY  \\n- **Previous Interactions:**  \\n  - A hotel search for New York was completed.  \\n  - A hotel search for Los Angeles was executed, returning 8 results (Hotel Aâ€“Hotel H), but the user has not yet selected a hotel.  \\n- **Current Action:** The user has explicitly requested a hotel search for **Chicago**, which will overwrite the prior Los Angeles focus.  \\n\\n## ARTIFACTS  \\n- **Tool Call (Pending):** `{\\'name\\': \\'search_hotel\\', \\'args\\': {\\'city\\': \\'Chicago\\'}, \\'id\\': \\'[new_tool_call_id]\\', \\'type\\': \\'tool_call\\'}`  \\n- **Previous Results (Los Angeles):**  \\n  ```  \\n  1. Hotel A  \\n  2. Hotel B  \\n  3. Hotel C  \\n  4. Hotel D  \\n  5. Hotel E  \\n  6. Hotel F  \\n  7. Hotel G  \\n  8. Hotel H  \\n  ```  \\n\\n## NEXT STEPS  \\n1. **Immediate:** Execute the `search_hotel` tool call for **Chicago** to retrieve results.  \\n2. **Follow-up:** Once results are available, present them to the user and prompt for selection or further details (e.g., preferences, booking).  \\n3. **Pending:** Address the unresolved Los Angeles hotel selection if the user revisits that task.', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='b323fe93-e0ae-448d-bb7c-42e595aa7273'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user wants to search for hotels in Chicago. Let me check the tools provided. There\\'s a function called search_hotel that takes a city parameter. The previous interactions show that when the user asked for New York and Los Angeles, the assistant called the search_hotel function with the respective city names. The response format includes a list of hotels, even though the tool response had some formatting issues, like inconsistent numbering. The assistant corrected that by listing them as 1 to 8.\\n\\nSo, for Chicago, I should follow the same pattern. First, call the search_hotel function with \"Chicago\" as the city. The user probably expects a list of hotels in Chicago, similar to the previous responses. Even if the tool\\'s raw response has formatting issues, the assistant should present the hotels in a clear, numbered list. The user might then ask for more details or booking help, but the immediate step is to provide the list. I need to make sure the function call is correctly formatted in JSON within the tool_call tags. No other functions are available, so this is the only action needed here.\\n', 'tool_calls': [{'id': 'n9qkkvprh', 'function': {'arguments': '{\"city\":\"Chicago\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 1030, 'total_tokens': 1280, 'completion_time': 0.531305441, 'completion_tokens_details': {'reasoning_tokens': 225}, 'prompt_time': 0.04741441, 'prompt_tokens_details': None, 'queue_time': 0.007331851, 'total_time': 0.578719851}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-a4b3-7a83-88c8-479f19b23e68-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'Chicago'}, 'id': 'n9qkkvprh', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1030, 'output_tokens': 250, 'total_tokens': 1280, 'output_token_details': {'reasoning': 225}}), ToolMessage(content='Hotels in city : Chicago:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='e03c526e-00e8-4c6c-8af4-562141fde3ea', tool_call_id='n9qkkvprh'), AIMessage(content='Here are the hotels in Chicago from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, the user asked for hotels in Chicago after previously searching for Los Angeles and New York. Let me check the pattern here. Each time they request a new city, I need to call the search_hotel function with that city\\'s name. The tool response format seems consistent, listing hotels in a numbered list with some indentation issues. \\n\\nThe user\\'s current query is \"Search for hotels in Chicago,\" so the immediate step is to invoke the search_hotel function again with \"Chicago\" as the city parameter. The previous responses from the tool have a similar structure, so I should expect the same here. Once the tool returns the list, I\\'ll need to present it in a user-friendly way, maybe fixing the formatting so the list is clear.\\n\\nWait, in the last interaction, after the tool response, I listed the hotels in a simple numbered list without the subpoints. The user might appreciate that format. So I\\'ll take the tool\\'s response for Chicago, parse the hotels, and present them neatly. Also, I should offer further assistance, like details or booking help, just like before. Let me make sure there\\'s no duplication or confusion in the list. Hotels A to H again? Maybe the tool uses the same names, but the user might not care as long as the options are clear. Alright, proceed to format the response and ask if they need more info.\\n'}, response_metadata={'token_usage': {'completion_tokens': 350, 'prompt_tokens': 1141, 'total_tokens': 1491, 'completion_time': 0.818370383, 'completion_tokens_details': {'reasoning_tokens': 279}, 'prompt_time': 0.049601736, 'prompt_tokens_details': None, 'queue_time': 0.006294784, 'total_time': 0.867972119}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9a-fd97-7091-aef1-e1f5b963572b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1141, 'output_tokens': 350, 'total_tokens': 1491, 'output_token_details': {'reasoning': 279}}), HumanMessage(content='Search for hotels in Houston', additional_kwargs={}, response_metadata={}, id='bf9aa9b6-2a76-4b75-93ac-993960c96ae2'), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user has been searching for hotels in different cities. First, they wanted New York, then Los Angeles, followed by Chicago, and now Houston. Each time, I called the search_hotel function with the respective city name. The pattern seems to be that the user is looking for hotel options in various locations, possibly for travel or business purposes.\\n\\nWhen the user asked for Houston this time, I need to continue the same process. The function requires the city parameter, so I\\'ll input \"Houston\" into the search_hotel tool. There\\'s no indication that the user wants anything different from previous searches, so the response should follow the same structure as before, listing the hotels once the function returns the data.\\n\\nI should make sure that each hotel is listed clearly, numbering them in order. Also, after providing the list, I should ask if they need more details or help with booking, which has been the standard follow-up. There\\'s no mention of any specific hotel preferences, so the response remains general. The user might be comparing hotels across cities or planning a trip that includes multiple stops. Either way, the task is to provide the information they need for each city they inquire about.\\n', 'tool_calls': [{'id': 'f0gg0y9n4', 'function': {'arguments': '{\"city\":\"Houston\"}', 'name': 'search_hotel'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 266, 'prompt_tokens': 1001, 'total_tokens': 1267, 'completion_time': 0.57181052, 'completion_tokens_details': {'reasoning_tokens': 241}, 'prompt_time': 0.044453104, 'prompt_tokens_details': None, 'queue_time': 0.00726948, 'total_time': 0.616263624}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9b-6f0b-77e1-bae4-ec90596a0cc2-0', tool_calls=[{'name': 'search_hotel', 'args': {'city': 'Houston'}, 'id': 'f0gg0y9n4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1001, 'output_tokens': 266, 'total_tokens': 1267, 'output_token_details': {'reasoning': 241}}), ToolMessage(content='Hotels in city : Houston:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    ', name='search_hotel', id='cac297d1-0d09-4352-96c5-0bd90ce85265', tool_call_id='f0gg0y9n4'), AIMessage(content='Here are the hotels in Houston from the search results:\\n\\n1. Hotel A  \\n2. Hotel B  \\n3. Hotel C  \\n4. Hotel D  \\n5. Hotel E  \\n6. Hotel F  \\n7. Hotel G  \\n8. Hotel H  \\n\\nWould you like more details about any of these options or assistance with booking?', additional_kwargs={'reasoning_content': 'Okay, let me try to figure out how to handle this. The user has been asking for hotels in different cities: first New York, then Los Angeles, Chicago, and now Houston. Each time, I used the search_hotel tool and got a list of hotels, which I formatted into a numbered list. The pattern seems to be that the user wants a clean list of hotels without any extra formatting.\\n\\nLooking at the latest response from the tool, the hotels in Houston are listed with some inconsistent numbering and indentation. My job is to present this information clearly. I need to make sure the list is properly numbered from 1 to 8, just like the previous responses. Also, the user might be looking for a straightforward list without any markdown, so I should keep it simple.\\n\\nWait, the tool_response for Houston has entries like \"    1. Hotel A\" with leading spaces. That\\'s probably a formatting error. I should correct that by removing the extra spaces and ensuring each hotel is listed with the correct number. Also, there\\'s a repetition in numbering, like \"3. Hotel C.\" followed by \"    2. Hotel D\". That seems off. I need to renumber them sequentially from 1 to 8.\\n\\nLet me parse the tool_response again. The raw data is:\\n\\nHotels in city : Houston:\\n    1. Hotel A\\n2. Hotel B\\n3. Hotel C.\\n    2. Hotel D\\n3. Hotel E.\\n    3. Hotel F\\n4. Hotel G\\n5. Hotel H.\\n    \\nSo, the correct approach is to list each hotel with a unique number from 1 to 8, removing any leading spaces and fixing the numbering. The user expects a clean, easy-to-read list. After formatting, I should ask if they need more details or booking help, as in previous interactions. That way, the user knows the next steps are available. I need to make sure the response is consistent with how I presented Chicago and Los Angeles results. Alright, let\\'s structure the list correctly and maintain the same follow-up question.\\n'}, response_metadata={'token_usage': {'completion_tokens': 497, 'prompt_tokens': 1182, 'total_tokens': 1679, 'completion_time': 1.030107169, 'completion_tokens_details': {'reasoning_tokens': 426}, 'prompt_time': 0.048832694, 'prompt_tokens_details': None, 'queue_time': 0.006738666, 'total_time': 1.078939863}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9b-d0c4-7aa3-a3c7-bb1c15f49e99-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1182, 'output_tokens': 497, 'total_tokens': 1679, 'output_token_details': {'reasoning': 426}})]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1024\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m cities = [\u001b[33m\"\u001b[39m\u001b[33mNew York\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLos Angeles\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChicago\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHouston\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPhoenix\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m cities:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSearch for hotels in \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcity\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     tokens = count_tokesn(response[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m messages\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\summarization.py:311\u001b[39m, in \u001b[36mSummarizationMiddleware.before_model\u001b[39m\u001b[34m(self, state, runtime)\u001b[39m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    309\u001b[39m messages_to_summarize, preserved_messages = \u001b[38;5;28mself\u001b[39m._partition_messages(messages, cutoff_index)\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m summary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages_to_summarize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m new_messages = \u001b[38;5;28mself\u001b[39m._build_new_messages(summary)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    315\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    316\u001b[39m         RemoveMessage(\u001b[38;5;28mid\u001b[39m=REMOVE_ALL_MESSAGES),\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m     ]\n\u001b[32m    320\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain\\agents\\middleware\\summarization.py:598\u001b[39m, in \u001b[36mSummarizationMiddleware._create_summary\u001b[39m\u001b[34m(self, messages_to_summarize)\u001b[39m\n\u001b[32m    595\u001b[39m formatted_messages = get_buffer_string(trimmed_messages)\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msummary_prompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatted_messages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlc_source\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msummarization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text.strip()\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:621\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    616\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    617\u001b[39m params = {\n\u001b[32m    618\u001b[39m     **params,\n\u001b[32m    619\u001b[39m     **kwargs,\n\u001b[32m    620\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:461\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    243\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    301\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1030\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1029\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Antigravity\\langchain\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1070\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1067\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1068\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cities = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"]\n",
    "for city in cities:\n",
    "    response = agent.invoke({\"messages\" : [HumanMessage(content=f\"Search for hotels in {city}\")]},config)\n",
    "\n",
    "    tokens = count_tokesn(response['messages'])\n",
    "    print(f\"{city} - Tokens: {tokens} tokens,{len(response['messages'])} messages\")\n",
    "    print(f\"{(response['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5b770",
   "metadata": {},
   "source": [
    "### Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: {'messages': [HumanMessage(content='What is 1/2 plus 1/3?', additional_kwargs={}, response_metadata={}, id='1a3aab8c-c7ef-4e99-9361-25f175c34a51'), AIMessage(content=\"<think>\\nOkay, so I need to figure out what 1/2 plus 1/3 is. Hmm, adding fractions. Let me think. I remember that to add fractions, they have to have the same denominator. Right? If the denominators are different, you can't just add the numerators directly. So first, I need to find a common denominator for 1/2 and 1/3. \\n\\nThe denominators here are 2 and 3. What's the least common denominator of 2 and 3? Well, the least common multiple of 2 and 3. Let me think. Multiples of 2 are 2, 4, 6, 8, 10, 12... and multiples of 3 are 3, 6, 9, 12... So the smallest common multiple is 6. So 6 is the least common denominator. \\n\\nOkay, so I need to convert both fractions to have 6 as the denominator. Starting with 1/2. To turn 2 into 6, I multiply the denominator by 3. So I have to do the same to the numerator. So 1 times 3 is 3, and denominator 2 times 3 is 6. So 1/2 is equivalent to 3/6. \\n\\nNow for 1/3. The denominator is 3, and we need to turn it into 6. Multiply denominator by 2, so 3 times 2 is 6. So numerator also has to be multiplied by 2. 1 times 2 is 2. So 1/3 is equivalent to 2/6. \\n\\nNow, adding the two converted fractions: 3/6 + 2/6. Since the denominators are the same, I can add the numerators. 3 + 2 is 5. So the sum is 5/6. \\n\\nWait, let me check if that's correct. If I add 1/2 and 1/3, does it equal 5/6? Let me verify with another method. Maybe convert them to decimals. 1/2 is 0.5, 1/3 is approximately 0.3333. Adding them together: 0.5 + 0.3333 = 0.8333... And 5/6 as a decimal is 0.8333... So that matches. Yeah, that seems right. \\n\\nAnother way to think about it: If I have half a pizza and a third of another pizza, how much do I have? If both pizzas are the same size, then converting to sixths, half is three sixths, third is two sixths. Total five sixths. That makes sense. \\n\\nIs there a way to do this without finding the least common denominator? Maybe by multiplying the denominators? Let's see. If I multiply 2 and 3, I get 6, which is the same as the LCD. So maybe that's why it works. But if denominators were not co-prime, like 4 and 6, then LCD is 12, but multiplying gives 24. So better to find LCD. But in this case, since 2 and 3 are co-prime, their product is the LCD. \\n\\nAlternatively, using the formula for adding fractions: (a/b + c/d) = (ad + bc)/bd. So here, a=1, b=2, c=1, d=3. Plugging in: (1*3 + 1*2)/(2*3) = (3 + 2)/6 = 5/6. Yep, same result. \\n\\nSo all methods lead to 5/6. Therefore, I think the answer is 5/6. \\n\\nJust to make sure I didn't make any arithmetic errors. Let me go through the steps again. \\n\\n1/2 = 3/6 because 1*3=3 and 2*3=6. Correct. 1/3 = 2/6 because 1*2=2 and 3*2=6. Correct. Adding 3/6 + 2/6 = 5/6. Yes. \\n\\nAlternatively, if I had chosen a different common denominator, like 12. Let's test that. 1/2 is 6/12, 1/3 is 4/12. Adding gives 10/12, which simplifies to 5/6. Same answer. So regardless of the common denominator chosen, as long as it's correct, the result is the same. \\n\\nSo, I think I've verified it multiple ways. The answer should be 5/6.\\n</think>\\n\\nTo solve the problem of adding the fractions $\\\\frac{1}{2} + \\\\frac{1}{3}$, we follow these key steps:\\n\\n---\\n\\n### Step 1: Find a Common Denominator\\n\\nTo add fractions, they must share the same denominator. The denominators in this case are 2 and 3. The **least common denominator (LCD)** of 2 and 3 is **6**, since 6 is the smallest number both 2 and 3 divide into evenly.\\n\\n---\\n\\n### Step 2: Convert Each Fraction to Have the Same Denominator\\n\\nWe convert each fraction to have the denominator 6:\\n\\n- $\\\\frac{1}{2} = \\\\frac{1 \\\\times 3}{2 \\\\times 3} = \\\\frac{3}{6}$\\n- $\\\\frac{1}{3} = \\\\frac{1 \\\\times 2}{3 \\\\times 2} = \\\\frac{2}{6}$\\n\\n---\\n\\n### Step 3: Add the Fractions\\n\\nNow that both fractions have the same denominator, we can add the numerators:\\n\\n$$\\n\\\\frac{3}{6} + \\\\frac{2}{6} = \\\\frac{3 + 2}{6} = \\\\frac{5}{6}\\n$$\\n\\n---\\n\\n### Step 4: Simplify if Necessary\\n\\nThe fraction $\\\\frac{5}{6}$ is already in its simplest form.\\n\\n---\\n\\n### Final Answer\\n\\n$$\\n\\\\boxed{\\\\frac{5}{6}}\\n$$\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1308, 'prompt_tokens': 20, 'total_tokens': 1328, 'completion_time': 2.182258454, 'completion_tokens_details': None, 'prompt_time': 0.0006327, 'prompt_tokens_details': None, 'queue_time': 0.006267243, 'total_time': 2.182891154}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9e-eded-7d03-b9b6-e56e6529a0b9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 20, 'output_tokens': 1308, 'total_tokens': 1328})]}\n",
      "Messages: {'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let\\'s tackle this. The user asked for the sum of 1/2 and 1/3. My job is to extract the most relevant context from the conversation history provided. \\n\\nFirst, I need to parse the AI\\'s thought process. The AI started by recognizing that adding fractions requires a common denominator. They correctly identified 6 as the LCD of 2 and 3. Then they converted each fraction to have 6 as the denominator: 1/2 becomes 3/6 and 1/3 becomes 2/6. Adding those gives 5/6.\\n\\nThe summary also includes verification steps like converting to decimals (0.5 + 0.333) and using an alternative method (cross-multiplication formula). They even tested another common denominator (12) to confirm the result. The answer was verified multiple times, so the conclusion is solid.\\n\\nNow, according to the instructions, I need to structure the extracted context into four sections: SESSION INTENT, SUMMARY, ARTIFACTS, NEXT STEPS. The SESSION INTENT is straightforwardâ€”it\\'s the user\\'s question. The SUMMARY should capture the method, key calculations, and verification. Since no files were created or modified, ARTIFACTS can be \"None.\" The NEXT STEPS are also \"None\" because the problem is solved and the answer is verified.\\n\\nI need to make sure the summary is concise but includes the essential steps and reasoning without unnecessary details. Also, avoid repeating information. The user\\'s goal was clear, and the AI achieved it, so the summary should reflect that completion.\\n</think>\\n\\n## SESSION INTENT  \\nCalculate the sum of the fractions $\\\\frac{1}{2}$ and $\\\\frac{1}{3}$.  \\n\\n## SUMMARY  \\nTo add $\\\\frac{1}{2}$ and $\\\\frac{1}{3}$, the least common denominator (LCD) of 2 and 3 was identified as 6. Both fractions were converted to equivalent forms with denominator 6: $\\\\frac{1}{2} = \\\\frac{3}{6}$ and $\\\\frac{1}{3} = \\\\frac{2}{6}$. The numerators were then added: $\\\\frac{3}{6} + \\\\frac{2}{6} = \\\\frac{5}{6}$. Verification methods included decimal conversion (0.5 + 0.333 = 0.833) and alternative denominator testing (e.g., using 12 as a common denominator, yielding $\\\\frac{10}{12} = \\\\frac{5}{6}$). All calculations confirmed the result $\\\\frac{5}{6}$ is correct and in simplest form.  \\n\\n## ARTIFACTS  \\nNone.  \\n\\n## NEXT STEPS  \\nNone. The session intent has been fully resolved.', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='5e0d37b3-3b84-4521-a519-42630bc56edd'), HumanMessage(content='What is 2+2?', additional_kwargs={}, response_metadata={}, id='ff6a5c95-3a7f-4454-a95c-d98fc946000e'), AIMessage(content='<think>\\nOkay, the user is asking \"What is 2+2?\" That\\'s a straightforward arithmetic question. Let me think about how to approach this.\\n\\nFirst, I need to recall basic addition. 2 plus 2 is a common question, and the answer should be 4. But wait, maybe I should verify it step by step to be thorough. Let\\'s break it down. Adding 2 and 2 means combining two groups of two. So, 2 + 2 equals 4. \\n\\nI should check if there\\'s any context or trick in the question. Sometimes people phrase questions in a way that might imply a different answer, like in base systems or wordplay. But \"2+2\" in standard decimal is definitely 4. The user might be testing if I know basic math or just wants a quick answer. \\n\\nSince there\\'s no complicating factor here, the answer is straightforward. I should present it clearly. Also, considering the previous interaction where the user asked about fractions, they might be working through basic math problems. It\\'s good to confirm the answer confidently but concisely.\\n</think>\\n\\n2 + 2 equals **4**. This is a fundamental arithmetic operation where the sum of the numbers 2 and 2 is calculated directly. No further steps or verification are needed for this simple case.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 273, 'prompt_tokens': 612, 'total_tokens': 885, 'completion_time': 0.600516268, 'completion_tokens_details': None, 'prompt_time': 0.026466593, 'prompt_tokens_details': None, 'queue_time': 0.006242767, 'total_time': 0.626982861}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9e-fcb7-79a3-ba5f-82531a354914-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 612, 'output_tokens': 273, 'total_tokens': 885})]}\n",
      "Messages: {'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let\\'s see. The user wants me to extract the most important context from the conversation history they provided. The instructions are to focus on the highest quality and most relevant information to continue working toward the overall goal, which is to replace the conversation history with a concise summary.\\n\\nFirst, I need to look at the messages provided. The first message from the human is a summary of the conversation to date where they asked for the sum of 1/2 and 1/3. The AI then went through the process of finding the least common denominator, converting the fractions, adding them, and verifying the result through different methods. The second message is the user asking \"What is 2+2?\" and the AI responding with \"4\" along with a brief explanation.\\n\\nMy task is to structure this into the four sections: SESSION INTENT, SUMMARY, ARTIFACTS, and NEXT STEPS. \\n\\nFor SESSION INTENT, the primary goal of the user seems to be solving basic arithmetic problems. First, they asked about fractions, then a simple addition. The overall session intent is to get correct answers to these math problems.\\n\\nIn the SUMMARY section, I need to extract the key steps and conclusions. For the first part, the user\\'s question involved adding fractions, which required finding a common denominator and converting. The answer was verified multiple times. For the second part, the user asked a simple addition, which was answered directly. I should mention both problems and their solutions concisely.\\n\\nARTIFACTS should list any files or resources created, but since there\\'s no mention of any in the conversation, I\\'ll put \"None\" there.\\n\\nNext steps are about what remains to be done. Since both questions have been answered, there\\'s nothing left, so \"None\" applies here too.\\n\\nI need to make sure the summary is concise but includes all critical information. The user\\'s intent is clear, and both problems were resolved. The AI provided correct answers and verification steps. I should avoid repeating actions already completed and focus on the outcomes.\\n</think>\\n\\n## SESSION INTENT  \\nAnswer basic arithmetic questions posed by the user (first about fraction addition, then about integer addition).  \\n\\n## SUMMARY  \\n1. **Fraction Addition**:  \\n   - Calculated $\\\\frac{1}{2} + \\\\frac{1}{3}$ by finding the least common denominator (LCD = 6), converting to $\\\\frac{3}{6} + \\\\frac{2}{6} = \\\\frac{5}{6}$.  \\n   - Verified the result using decimal conversion (0.833) and an alternative denominator (12 â†’ $\\\\frac{10}{12} = \\\\frac{5}{6}$).  \\n\\n2. **Integer Addition**:  \\n   - Directly answered $2 + 2 = 4$, confirming it is a basic arithmetic identity with no further steps required.  \\n\\n## ARTIFACTS  \\nNone.  \\n\\n## NEXT STEPS  \\nNone. All user questions have been resolved with verified answers.', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='e2b5e409-0394-4509-96e4-b1beb4e6ff2f'), HumanMessage(content='Calculate 3/4 times 2/5.', additional_kwargs={}, response_metadata={}, id='f8eb86a5-e916-4bac-925e-9db65cb7be32'), AIMessage(content=\"<think>\\nOkay, the user wants me to calculate 3/4 times 2/5. Let me start by recalling how to multiply fractions. I think the process is straightforward: multiply the numerators together and the denominators together. So 3 times 2 is 6, and 4 times 5 is 20. That gives 6/20. Then I need to simplify that fraction. Both 6 and 20 are divisible by 2, so dividing numerator and denominator by 2 gives 3/10. Let me double-check that. Yes, 6 divided by 2 is 3, and 20 divided by 2 is 10. So the simplified result is 3/10. Alternatively, I can verify by converting the fractions to decimals first. 3/4 is 0.75 and 2/5 is 0.4. Multiplying those gives 0.75 * 0.4 = 0.3, and 3/10 is 0.3, so that matches. Another way is cross-simplifying before multiplying. If I divide 3 and 5 by a common factor, but wait, 3 and 5 don't have common factors. Maybe I can cross-cancel with 4 and 2. The 4 and 2 can be simplified. Dividing 4 by 2 gives 2, and 2 by 2 gives 1. Then the problem becomes 3/2 * 1/5 = 3/10. Same result. Okay, that confirms the answer is correct. The user might just need the final answer, but explaining the steps would help them understand. Since the previous interactions involved verifying through multiple methods, I should include both the direct multiplication and the decimal verification to ensure clarity.\\n</think>\\n\\n## SESSION INTENT  \\nSolve the multiplication of fractions: $\\\\frac{3}{4} \\\\times \\\\frac{2}{5}$.  \\n\\n## SUMMARY  \\n1. **Multiplication Steps**:  \\n   - Multiply numerators: $3 \\\\times 2 = 6$.  \\n   - Multiply denominators: $4 \\\\times 5 = 20$.  \\n   - Result: $\\\\frac{6}{20}$, which simplifies to $\\\\frac{3}{10}$ (dividing numerator and denominator by 2).  \\n\\n2. **Verification**:  \\n   - Decimal conversion: $0.75 \\\\times 0.4 = 0.3$, equivalent to $\\\\frac{3}{10}$.  \\n   - Cross-simplification: Divide 4 and 2 by 2 before multiplying: $\\\\frac{3}{2} \\\\times \\\\frac{1}{5} = \\\\frac{3}{10}$.  \\n\\n## ARTIFACTS  \\nNone.  \\n\\n## NEXT STEPS  \\nNone. The calculation is complete and verified.  \\n\\nFinal Answer: $\\\\boxed{\\\\frac{3}{10}}$\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 619, 'prompt_tokens': 653, 'total_tokens': 1272, 'completion_time': 1.053101105, 'completion_tokens_details': None, 'prompt_time': 0.029835841, 'prompt_tokens_details': None, 'queue_time': 0.007137786, 'total_time': 1.082936946}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9f-051c-7650-aea1-af5cac278135-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 653, 'output_tokens': 619, 'total_tokens': 1272})]}\n",
      "Messages: {'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let\\'s see. The user provided a conversation history where they asked for the product of 3/4 and 2/5. The AI correctly multiplied the numerators and denominators, simplified the result, and verified it through decimal conversion and cross-simplification. The user now wants me to extract the most relevant context from this interaction to replace the full conversation history.\\n\\nFirst, I need to identify the session intent. The primary goal here was to calculate the multiplication of two fractions, which the user asked for. That\\'s straightforward.\\n\\nNext, the summary section should capture the key steps and verification methods. The AI multiplied numerators (3*2=6), denominators (4*5=20), simplified 6/20 to 3/10, and confirmed with decimal equivalents (0.75*0.4=0.3) and cross-simplification. All these steps are important for understanding the process and ensuring accuracy.\\n\\nArtifacts are files or resources created, but in this case, nothing was created, so \"None\" applies here. The next steps are also \"None\" since the problem is resolved. \\n\\nI need to structure this information concisely under the four sections. Make sure to mention the calculation steps, methods of verification, and the final answer. Avoid any extra details that don\\'t contribute to the main goal of solving the multiplication problem. Check that the summary doesn\\'t repeat actions already completed and stays focused on the essential information. Everything seems covered in the provided answer, so I\\'ll format it accordingly.\\n</think>\\n\\n## SESSION INTENT  \\nSolve the multiplication of fractions: $\\\\frac{3}{4} \\\\times \\\\frac{2}{5}$.  \\n\\n## SUMMARY  \\n1. **Multiplication Steps**:  \\n   - Numerators multiplied: $3 \\\\times 2 = 6$.  \\n   - Denominators multiplied: $4 \\\\times 5 = 20$.  \\n   - Resulting fraction: $\\\\frac{6}{20}$, simplified to $\\\\frac{3}{10}$ by dividing numerator and denominator by 2.  \\n\\n2. **Verification Methods**:  \\n   - Decimal cross-check: $0.75 \\\\times 0.4 = 0.3 = \\\\frac{3}{10}$.  \\n   - Cross-simplification: Reduced $\\\\frac{3}{4} \\\\times \\\\frac{2}{5}$ to $\\\\frac{3}{2} \\\\times \\\\frac{1}{5} = \\\\frac{3}{10}$.  \\n\\n## ARTIFACTS  \\nNone.  \\n\\n## NEXT STEPS  \\nNone. The calculation is complete and confirmed.', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='75edbc8f-f6a6-4200-ac4d-f4b74f956412'), HumanMessage(content='Add 5 and 7.Explain the process of photosynthesis in detail.', additional_kwargs={}, response_metadata={}, id='6368fc47-0f1f-44cf-803c-a6ba945ba2cc'), AIMessage(content=\"<think>\\nOkay, the user has given me two separate tasks here. First, they want me to add 5 and 7, which is straightforward. Then they want a detailed explanation of photosynthesis. Let me break this down.\\n\\nStarting with the addition: 5 + 7. That's simple arithmetic. The sum is 12. I'll just confirm that by counting or using basic math facts. No issues there.\\n\\nNow, the photosynthesis part. The user asked for a detailed explanation. I need to recall the process step by step. Let me start by outlining the main stages: light-dependent reactions and the Calvin cycle (light-independent reactions). \\n\\nFor the light-dependent reactions, I should mention where they occurâ€”in the thylakoid membranes of the chloroplasts. The process involves chlorophyll absorbing light, splitting water into oxygen, protons, and electrons (photolysis). This produces ATP and NADPH, which are energy carriers.\\n\\nThen the Calvin cycle happens in the stroma. It uses ATP and NADPH to fix carbon dioxide into glucose. I need to explain the three main steps: carbon fixation, reduction, and regeneration of the starting molecule (RuBP). Enzymes like RuBisCO are important here. Also, the role of ATP and NADPH in providing energy and electrons.\\n\\nWait, did I miss anything? Maybe the overall equation: 6CO2 + 6H2O â†’ C6H12O6 + 6O2. That's a good summary. Also, the importance of chlorophyll and other pigments in capturing light energy. Oh, and the two types of photosynthesis in different plants, like C3, C4, and CAM, but the user didn't ask for that detail, so maybe keep it basic.\\n\\nI should structure the explanation clearly, starting with the purpose of photosynthesis, then the two main stages, and the overall equation. Make sure to use simple language and avoid jargon where possible. Check that each step is explained logically, connecting the light-dependent and light-independent reactions. Also, mention the role of chloroplasts and the necessity of sunlight.\\n\\nDouble-check the steps for accuracy. For example, in the Calvin cycle, the first step is fixing CO2 with RuBP, catalyzed by RuBisCO. Then the six-carbon compound splits into two 3-PGA molecules, which are reduced using ATP and NADPH to form G3P. Some G3P molecules go to glucose, while others regenerate RuBP. Need to mention that the cycle requires 3 turns to produce one G3P for glucose.\\n\\nAlso, highlight that oxygen is a byproduct from the splitting of water during light-dependent reactions. That's a key point. Make sure the explanation is comprehensive but not overly technical unless the user requests more depth. Alright, that should cover the detailed explanation they need.\\n</think>\\n\\n### **1. Addition of 5 and 7**  \\nThe sum of 5 and 7 is **12**. This is a basic arithmetic operation where 5 is added to 7, resulting in 12.  \\n\\n---\\n\\n### **2. Photosynthesis: A Detailed Explanation**  \\n\\n#### **Purpose of Photosynthesis**  \\nPhotosynthesis is the process by which green plants, algae, and some bacteria convert sunlight, carbon dioxide (COâ‚‚), and water (Hâ‚‚O) into glucose (Câ‚†Hâ‚â‚‚Oâ‚†), oxygen (Oâ‚‚), and energy (ATP). It sustains life by producing oxygen and forming the foundation of the food chain.  \\n\\n---\\n\\n#### **Stages of Photosynthesis**  \\n\\n**1. Light-Dependent Reactions (Light Reactions)**  \\n- **Location**: Thylakoid membranes of chloroplasts.  \\n- **Process**:  \\n  - **Light Absorption**: Chlorophyll in chloroplasts absorbs sunlight.  \\n  - **Water Splitting (Photolysis)**: Water molecules are split into oxygen (Oâ‚‚), protons (Hâº), and electrons (eâ»).  \\n  - **Electron Transport Chain**: Electrons pass through proteins in the thylakoid membrane, releasing energy to pump protons into the thylakoid lumen.  \\n  - **ATP and NADPH Formation**:  \\n    - ATP is produced via **chemiosmosis** (protons flow through ATP synthase).  \\n    - NADPH is formed by electrons reducing NADPâº.  \\n\\n**2. Light-Independent Reactions (Calvin Cycle)**  \\n- **Location**: Stroma of chloroplasts.  \\n- **Process**:  \\n  - **Carbon Fixation**: COâ‚‚ from the atmosphere is combined with RuBP (a 5-carbon molecule) by the enzyme **RuBisCO**, forming 3-PGA (3-phosphoglycerate).  \\n  - **Reduction**: ATP and NADPH from light reactions provide energy and electrons to convert 3-PGA into G3P (glyceraldehyde-3-phosphate).  \\n  - **Regeneration of RuBP**: Most G3P molecules are recycled to regenerate RuBP, requiring additional ATP.  \\n  - **Glucose Formation**: For every 3 COâ‚‚ molecules processed (3 turns of the cycle), 1 G3P molecule exits to form glucose (Câ‚†Hâ‚â‚‚Oâ‚†).  \\n\\n---\\n\\n#### **Overall Equation**  \\n$$\\n6\\\\text{CO}_2 + 6\\\\text{H}_2\\\\text{O} + \\\\text{light energy} \\\\rightarrow \\\\text{C}_6\\\\text{H}_{12}\\\\text{O}_6 + 6\\\\text{O}_2\\n$$  \\n\\n---\\n\\n#### **Key Components**  \\n- **Chlorophyll**: Captures light energy.  \\n- **ATP/NADPH**: Energy carriers produced in light reactions.  \\n- **RuBisCO**: The enzyme responsible for carbon fixation.  \\n\\n---\\n\\n#### **Significance**  \\n- Produces oxygen as a byproduct, essential for aerobic life.  \\n- Converts solar energy into chemical energy (glucose), forming the basis of food and energy for ecosystems.  \\n\\nLet me know if you'd like further details (e.g., variations in C3, C4, or CAM plants)!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1301, 'prompt_tokens': 593, 'total_tokens': 1894, 'completion_time': 2.52528878, 'completion_tokens_details': None, 'prompt_time': 0.02539279, 'prompt_tokens_details': None, 'queue_time': 0.006168315, 'total_time': 2.55068157}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3d9f-71e1-7fe2-b60a-907eb5998810-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 593, 'output_tokens': 1301, 'total_tokens': 1894})]}\n"
     ]
    }
   ],
   "source": [
    "# Example: SummarizationMiddleware with Fraction Trigger for Tokens\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# Fraction trigger: summarize when tokens exceed 0.005 of max tokens (e.g., 0.5%)\n",
    "fraction = 0.005\n",
    "max_tokens = 1000  # Example max tokens\n",
    "trigger_tokens = int(max_tokens * fraction)\n",
    "keep_tokens = int(max_tokens * 0.2)  # Keep 20% of max tokens\n",
    "\n",
    "agent = create_agent(\n",
    "    model='groq:qwen/qwen3-32b',\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model='groq:qwen/qwen3-32b',\n",
    "            trigger=(\"tokens\", trigger_tokens),\n",
    "            keep=(\"tokens\", keep_tokens),\n",
    "        )\n",
    "]\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"What is 1/2 plus 1/3?\",\n",
    "    \"What is 2+2?\",\n",
    "    \"Calculate 3/4 times 2/5.\",\n",
    "    \"Add 5 and 7.\"\n",
    "    # Add more questions to reach token threshold\n",
    "    \"Explain the process of photosynthesis in detail.\",\n",
    "    \"Describe the history of the Roman Empire.\",\n",
    "    \"What are the main causes of climate change?\"\n",
    "]\n",
    "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
    "for q in questions:\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=q)]},config)\n",
    "    print(f\"Messages: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5260c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
